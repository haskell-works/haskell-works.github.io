<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Haskell Works Blog</title>
    <link href="https://haskell-works.github.io/atom.xml" rel="self" />
    <link href="https://haskell-works.github.io" />
    <id>https://haskell-works.github.io/atom.xml</id>
    <author>
        <name>Haskell Works</name>
        <email></email>
    </author>
    <updated>2018-09-21T00:00:00Z</updated>
    <entry>
    <title>Rechunking lazy bytestrings</title>
    <link href="https://haskell-works.github.io/posts/2018-09-21-rechunking-lazy-bytestrings.html" />
    <id>https://haskell-works.github.io/posts/2018-09-21-rechunking-lazy-bytestrings.html</id>
    <published>2018-09-21T00:00:00Z</published>
    <updated>2018-09-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In the <a href="../posts/2018-09-03-simd-with-linecount.html">previous post</a>, we’ve established that we want to use SIMD for speed.</p>
<p>We’d also like our CSV parser stream the data to avoid excessive memory usage so we’re going to have to read the CSV input in chunks.</p>
<p>Given that SIMD registers are currently up to 512-bits in size, the chunk size will need to be multiples of 64-bytes to work with arbitrary SIMD instructions.</p>
<p>This post will look at the chunk size Haskell’s <a href="http://hackage.haskell.org/package/bytestring"><code>bytestring</code></a> library actually gives us and explore some ways we can get the required chunk size we need.</p>
<h1 id="lazy-io">Lazy IO</h1>
<p>Due to laziness, streaming in Haskell is straightforward. The following function lazily reads the entire contents of the input file and writes them into the output file.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">import</span> <span class="kw">qualified</span> <span class="dt">Data.ByteString.Lazy</span> <span class="kw">as</span> <span class="dt">LBS</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="ot">cat ::</span> FilePath <span class="ot">-&gt;</span> FilePath <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</a>
<a class="sourceLine" id="cb1-4" data-line-number="4">cat inputFile outputFile <span class="fu">=</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5">  bs <span class="ot">&lt;-</span> LBS.readFile inputFile</a>
<a class="sourceLine" id="cb1-6" data-line-number="6">  LBS.writeFile outputFile bs</a></code></pre></div>
<p>For efficiency, the lazy bytestring is actually very similar in structure to a list of strict bytestrings. Each bytestring represents a chunk of the input file contents with a <a href="http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/src/Data.ByteString.Lazy.Internal.html#defaultChunkSize">carefully chosen chunk size</a> to maximise performance.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="ot">defaultChunkSize ::</span> <span class="dt">Int</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">defaultChunkSize <span class="fu">=</span> <span class="dv">32</span> <span class="fu">*</span> k <span class="fu">-</span> chunkOverhead</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">   <span class="kw">where</span> k <span class="fu">=</span> <span class="dv">1024</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="ot">chunkOverhead ::</span> <span class="dt">Int</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6">chunkOverhead <span class="fu">=</span> <span class="dv">2</span> <span class="fu">*</span> sizeOf (undefined<span class="ot"> ::</span> <span class="dt">Int</span>)</a></code></pre></div>
<p>Evideence of this behaviour is observable by using the <a href="http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/Data-ByteString-Lazy.html#v:toChunks"><code>toChunks</code></a> function to convert the lazy bytestring and inspecting their size5.</p>
<p>The following command reads a file with lazy IO and counts the frequency of each chunk size:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="fu">$</span> git clone git<span class="fu">@</span>github<span class="fu">.</span>com<span class="fu">:</span>haskell<span class="fu">-</span>works<span class="fu">/</span>hw<span class="fu">-</span>simd<span class="fu">-</span>cli<span class="fu">.</span>git</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="fu">$</span> cd hw<span class="fu">-</span>simd<span class="fu">-</span>cli</a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="fu">$</span> git checkout 2a9dadf9291cad68f2b05917619861eead3c31dd</a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="fu">$</span> <span class="fu">./</span>project<span class="fu">.</span>sh install</a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="fu">$</span> hw<span class="fu">-</span>simd chunks <span class="fu">-</span>i <span class="fu">~/</span>7g<span class="fu">.</span>csv <span class="fu">-</span>m chunked <span class="fu">-</span>r classic</a>
<a class="sourceLine" id="cb3-6" data-line-number="6"><span class="dt">Total</span> chunks<span class="fu">:</span> <span class="dv">232230</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7"><span class="dt">Chunk</span> histogram<span class="fu">:</span></a>
<a class="sourceLine" id="cb3-8" data-line-number="8"><span class="dv">2350</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb3-9" data-line-number="9"><span class="dv">32752</span>,<span class="dv">232229</span></a></code></pre></div>
<p>Unfortunately for us, this chunk size is no good for using SIMD instructions that can use registers up to 512-bits or 64-bytes.</p>
<p>More interestingly, even had the <code>defaultChunkSize</code> been set to a more convenient size of being a multiple of 64-bytes, a 64-byte multiple chunk size is not guaranteed, as shown in this example where we read from standard input instead:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="fu">$</span> cat <span class="fu">~/</span>7g<span class="fu">.</span>csv <span class="fu">|</span> time hw<span class="fu">-</span>simd chunks <span class="fu">-</span>i <span class="fu">-</span> <span class="fu">-</span>m chunked <span class="fu">-</span>r classic</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="dt">Total</span> chunks<span class="fu">:</span> <span class="dv">279332</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="dt">Chunk</span> histogram<span class="fu">:</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="dv">16</span>,<span class="dv">5780</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="dv">32</span>,<span class="dv">5882</span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6"><span class="dv">48</span>,<span class="dv">1793</span></a>
<a class="sourceLine" id="cb4-7" data-line-number="7"><span class="dv">64</span>,<span class="dv">739</span></a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="dv">80</span>,<span class="dv">400</span></a>
<a class="sourceLine" id="cb4-9" data-line-number="9"><span class="dv">96</span>,<span class="dv">239</span></a>
<a class="sourceLine" id="cb4-10" data-line-number="10"><span class="dv">112</span>,<span class="dv">130</span></a>
<a class="sourceLine" id="cb4-11" data-line-number="11"><span class="dv">128</span>,<span class="dv">77</span></a>
<a class="sourceLine" id="cb4-12" data-line-number="12"><span class="dv">144</span>,<span class="dv">55</span></a>
<a class="sourceLine" id="cb4-13" data-line-number="13"><span class="dv">160</span>,<span class="dv">50</span></a>
<a class="sourceLine" id="cb4-14" data-line-number="14"><span class="dv">176</span>,<span class="dv">32</span></a>
<a class="sourceLine" id="cb4-15" data-line-number="15"><span class="dv">192</span>,<span class="dv">20</span></a>
<a class="sourceLine" id="cb4-16" data-line-number="16"><span class="dv">208</span>,<span class="dv">16</span></a>
<a class="sourceLine" id="cb4-17" data-line-number="17"><span class="dv">224</span>,<span class="dv">12</span></a>
<a class="sourceLine" id="cb4-18" data-line-number="18"><span class="dv">240</span>,<span class="dv">5</span></a>
<a class="sourceLine" id="cb4-19" data-line-number="19"><span class="dv">256</span>,<span class="dv">7</span></a>
<a class="sourceLine" id="cb4-20" data-line-number="20"><span class="dv">272</span>,<span class="dv">9</span></a>
<a class="sourceLine" id="cb4-21" data-line-number="21"><span class="dv">288</span>,<span class="dv">8</span></a>
<a class="sourceLine" id="cb4-22" data-line-number="22"><span class="dv">304</span>,<span class="dv">8</span></a>
<a class="sourceLine" id="cb4-23" data-line-number="23"><span class="dv">320</span>,<span class="dv">2</span></a>
<a class="sourceLine" id="cb4-24" data-line-number="24"><span class="dv">336</span>,<span class="dv">5</span></a>
<a class="sourceLine" id="cb4-25" data-line-number="25"><span class="dv">368</span>,<span class="dv">3</span></a>
<a class="sourceLine" id="cb4-26" data-line-number="26"><span class="dv">384</span>,<span class="dv">2</span></a>
<a class="sourceLine" id="cb4-27" data-line-number="27"><span class="dv">400</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-28" data-line-number="28"><span class="dv">416</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-29" data-line-number="29"><span class="dv">432</span>,<span class="dv">3</span></a>
<a class="sourceLine" id="cb4-30" data-line-number="30"><span class="dv">448</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-31" data-line-number="31"><span class="dv">464</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-32" data-line-number="32"><span class="dv">480</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-33" data-line-number="33"><span class="dv">496</span>,<span class="dv">4</span></a>
<a class="sourceLine" id="cb4-34" data-line-number="34"><span class="dv">512</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-35" data-line-number="35"><span class="dv">544</span>,<span class="dv">3</span></a>
<a class="sourceLine" id="cb4-36" data-line-number="36"><span class="dv">560</span>,<span class="dv">3</span></a>
<a class="sourceLine" id="cb4-37" data-line-number="37"><span class="dv">592</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-38" data-line-number="38"><span class="dv">640</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-39" data-line-number="39"><span class="dv">704</span>,<span class="dv">2</span></a>
<a class="sourceLine" id="cb4-40" data-line-number="40"><span class="dv">1088</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-41" data-line-number="41"><span class="dv">1184</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-42" data-line-number="42"><span class="dv">1280</span>,<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-43" data-line-number="43"><span class="dv">16384</span>,<span class="dv">8555</span></a>
<a class="sourceLine" id="cb4-44" data-line-number="44"><span class="dv">16400</span>,<span class="dv">10125</span></a>
<a class="sourceLine" id="cb4-45" data-line-number="45"><span class="dv">16416</span>,<span class="dv">23140</span></a>
<a class="sourceLine" id="cb4-46" data-line-number="46"><span class="dv">16432</span>,<span class="dv">9269</span></a>
<a class="sourceLine" id="cb4-47" data-line-number="47"><span class="dv">16448</span>,<span class="dv">4729</span></a>
<a class="sourceLine" id="cb4-48" data-line-number="48"><span class="dv">16464</span>,<span class="dv">2883</span></a>
<a class="sourceLine" id="cb4-49" data-line-number="49"><span class="dv">16480</span>,<span class="dv">1683</span></a>
<a class="sourceLine" id="cb4-50" data-line-number="50"><span class="dv">16496</span>,<span class="dv">1005</span></a>
<a class="sourceLine" id="cb4-51" data-line-number="51"><span class="dv">16512</span>,<span class="dv">669</span></a>
<a class="sourceLine" id="cb4-52" data-line-number="52"><span class="dv">16528</span>,<span class="dv">433</span></a>
<a class="sourceLine" id="cb4-53" data-line-number="53"><span class="dv">16544</span>,<span class="dv">303</span></a>
<a class="sourceLine" id="cb4-54" data-line-number="54"><span class="dv">16560</span>,<span class="dv">202</span></a>
<a class="sourceLine" id="cb4-55" data-line-number="55"><span class="dv">16576</span>,<span class="dv">160</span></a>
<a class="sourceLine" id="cb4-56" data-line-number="56"><span class="dv">16592</span>,<span class="dv">95</span></a>
<a class="sourceLine" id="cb4-57" data-line-number="57"><span class="dv">16608</span>,<span class="dv">86</span></a>
<a class="sourceLine" id="cb4-58" data-line-number="58"><span class="dv">16624</span>,<span class="dv">60</span></a>
<a class="sourceLine" id="cb4-59" data-line-number="59"><span class="dv">16640</span>,<span class="dv">53</span></a>
<a class="sourceLine" id="cb4-60" data-line-number="60"><span class="dv">16656</span>,<span class="dv">36</span></a>
<a class="sourceLine" id="cb4-61" data-line-number="61"><span class="dv">16672</span>,<span class="dv">43</span></a>
<a class="sourceLine" id="cb4-62" data-line-number="62"><span class="dv">16688</span>,<span class="dv">29</span></a>
<a class="sourceLine" id="cb4-63" data-line-number="63"><span class="dv">16704</span>,<span class="dv">38</span></a>
<a class="sourceLine" id="cb4-64" data-line-number="64"><span class="dv">16720</span>,<span class="dv">23</span></a>
<a class="sourceLine" id="cb4-65" data-line-number="65"><span class="dv">16736</span>,<span class="dv">13</span></a>
<a class="sourceLine" id="cb4-66" data-line-number="66"><span class="dv">16752</span>,<span class="dv">13</span></a>
<a class="sourceLine" id="cb4-67" data-line-number="67"><span class="dv">16768</span>,<span class="dv">20</span></a>
<a class="sourceLine" id="cb4-68" data-line-number="68"><span class="dv">16784</span>,<span class="dv">15</span></a>
<a class="sourceLine" id="cb4-69" data-line-number="69"><span class="dv">16800</span>,<span class="dv">8</span></a>
<a class="sourceLine" id="cb4-70" data-line-number="70"><span class="dv">16816</span>,<span class="dv">14</span></a>
<a class="sourceLine" id="cb4-71" data-line-number="71"><span class="dv">16832</span>,<span class="dv">9</span></a>
<a class="sourceLine" id="cb4-72" data-line-number="72"><span class="dv">16848</span>,<span class="dv">8</span></a>
<a class="sourceLine" id="cb4-73" data-line-number="73"><span class="dv">16864</span>,<span class="dv">7</span></a>
<a class="sourceLine" id="cb4-74" data-line-number="74"><span class="dv">16880</span>,<span class="dv">7</span></a>
<a class="sourceLine" id="cb4-75" data-line-number="75"><span class="dv">16896</span>,<span class="dv">2</span></a>
<a class="sourceLine" id="cb4-76" data-line-number="76"><span class="dv">16912</span>,<span class="dv">4</span></a>
<a class="sourceLine" id="cb4-77" data-line-number="77"><span class="dv">16928</span>,<span class="dv">9</span></a>
<a class="sourceLine" id="cb4-78" data-line-number="78"><span class="dv">16944</span>,<span class="dv">11</span></a>
<a class="sourceLine" id="cb4-79" data-line-number="79"><span class="dv">16960</span>,<span class="dv">10</span></a>
<a class="sourceLine" id="cb4-80" data-line-number="80"><span class="dv">16976</span>,<span class="dv">9</span></a>
<a class="sourceLine" id="cb4-81" data-line-number="81"><span class="dv">16992</span>,<span class="dv">11</span></a></code></pre></div>
<h1 id="rechunking-resegmenting">Rechunking &amp; resegmenting</h1>
<p>One strategy we could use to ensure our bytestrings are always chunked to 64-byte multiples is to <a href="http://hackage.haskell.org/package/hw-prim-0.6.2.15/docs/HaskellWorks-Data-ByteString.html#v:rechunk"><code>rechunk</code></a> the bytestrings into equal chunk sizes like the following:</p>
<pre class="text"><code>|---------------a---------------|---------b----------|-c-|-------------d---------------|
|-d--|-e--|-f--|-g--|-h--|-i--|=j==|-k--|-l--|-m--|=n==|=o==|-p--|-q--|-r--|-s--|-t--|u|</code></pre>
<p>In the above, the chunks <code>d</code>-<code>i</code>, <code>k</code>-<code>m</code>, and <code>p</code>-<code>u</code> don’t require any byte copying because they are strict substrings of the chunks <code>a</code>, <code>b</code> and <code>d</code> respectively.</p>
<p><code>j</code>, <code>n</code>, and <code>o</code> however do require copy because their bytes come from multipe source chunks.</p>
<p>The need for copying is denoted by using the <code>=</code> characters.</p>
<p>The above scheme may minimise the amount of byte copying, but it is still fairly expensive because many bytestring objects are created.</p>
<p>4o reduce the number of bytestring objects, another approach is to <a href="http://hackage.haskell.org/package/hw-prim-0.6.2.15/docs/HaskellWorks-Data-ByteString.html#v:resegment"><code>resegment</code></a> the data instead.</p>
<p>This process is shown below:</p>
<pre class="text"><code>|---------------a---------------|---------b----------|-c-|-------------d---------------|
|--------------v--------------|=j==|------w-------|=n==|=o==|-----------x------------|k|</code></pre>
<p>Here, chunks <code>v</code>, <code>w</code> and <code>x</code> are created with a size that is the largest multiple of the chunk size allowed by the source chunk that is equivalent to the concatenation of the <code>d</code>-<code>i</code>, <code>k</code>-<code>m</code>, and <code>p</code>-<code>u</code> chunks in the <code>rechunk</code> example.</p>
<p>This gets us to the point where all except the last chunk is a multiple of the chunk size.</p>
<p>For doing our SIMD operations, we’d like all the chunks to be a multiple of the chunk size so <a href="http://hackage.haskell.org/package/hw-prim-0.6.2.15/docs/HaskellWorks-Data-ByteString.html#v:resegmentPadded"><code>resegmentPadded</code></a> will pad the last chunk to the chunk size with 0 bytes:</p>
<pre class="text"><code>|---------------a---------------|---------b----------|-c-|-------------d---------------|
|--------------v--------------|=j==|------w-------|=n==|=o==|-----------x------------|=y==|</code></pre>
<p>For clarity, I provide the diagrams for each strategy side-by-side:</p>
<pre class="text"><code>rechunk:          |-d--|-e--|-f--|-g--|-h--|-i--|=j==|-k--|-l--|-m--|=n==|=o==|-p--|-q--|-r--|-s--|-t--|u|
resegment:        |--------------v--------------|=j==|------w-------|=n==|=o==|-----------x------------|k|
resegmentPadded:  |--------------v--------------|=j==|------w-------|=n==|=o==|-----------x------------|=y==|</code></pre>
<p>Some benchmarking will give us some idea of how much rechunking and resegmenting costs us:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb9-1" data-line-number="1">$ <span class="fu">git</span> clone git@github.com:haskell-works/hw-simd-cli.git</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">$ <span class="bu">cd</span> hw-simd-cli</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">$ <span class="ex">./project.sh</span> install</a>
<a class="sourceLine" id="cb9-4" data-line-number="4">$ <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="kw">|</span> <span class="ex">hw-simd</span> cat -i - -o - -m default <span class="op">&gt;</span> /dev/null</a>
<a class="sourceLine" id="cb9-5" data-line-number="5"><span class="ex">7.08GiB</span> 0:00:05 [1.27GiB/s]</a>
<a class="sourceLine" id="cb9-6" data-line-number="6">$ <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="kw">|</span> <span class="ex">hw-simd</span> cat -i - -o - -m rechunk -c 64 <span class="op">&gt;</span> /dev/null</a>
<a class="sourceLine" id="cb9-7" data-line-number="7"><span class="ex">7.08GiB</span> 0:00:22 [ 317MiB/s]</a>
<a class="sourceLine" id="cb9-8" data-line-number="8">$ <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="kw">|</span> <span class="ex">hw-simd</span> cat -i - -o - -m resegment -c 64 <span class="op">&gt;</span> /dev/null</a>
<a class="sourceLine" id="cb9-9" data-line-number="9"><span class="ex">7.08GiB</span> 0:00:06 [1.15GiB/s]</a></code></pre></div>
<p>The results show the cost of using small chunks is drastic compared to the much more modest overhead of resegmenting.</p>
<h1 id="pre-chunked-reading">Pre-chunked reading</h1>
<p>An alternative to resegmenting the lazy bytestring is to read the bytes with the desired segment size in the first place.</p>
<p>The <a href="http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/Data-ByteString-Lazy.html#v:hGetContents"><code>hGetContents</code></a> function from the <a href="http://hackage.haskell.org/package/bytestring"><code>bytestring</code></a> library is implemented in terms of <a href="http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/src/Data.ByteString.Lazy.html#hGetContentsN"><code>hGetContentsN</code></a> like this:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="ot">hGetContentsN ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Handle</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">ByteString</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2">hGetContentsN k h <span class="fu">=</span> lazyRead <span class="co">-- TODO close on exceptions</span></a>
<a class="sourceLine" id="cb10-3" data-line-number="3">  <span class="kw">where</span></a>
<a class="sourceLine" id="cb10-4" data-line-number="4">    lazyRead <span class="fu">=</span> unsafeInterleaveIO loop</a>
<a class="sourceLine" id="cb10-5" data-line-number="5"></a>
<a class="sourceLine" id="cb10-6" data-line-number="6">    loop <span class="fu">=</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7">        c <span class="ot">&lt;-</span> S.hGetSome h k <span class="co">-- only blocks if there is no data available</span></a>
<a class="sourceLine" id="cb10-8" data-line-number="8">        <span class="kw">if</span> S.null c</a>
<a class="sourceLine" id="cb10-9" data-line-number="9">          <span class="kw">then</span> hClose h <span class="fu">&gt;&gt;</span> return <span class="dt">Empty</span></a>
<a class="sourceLine" id="cb10-10" data-line-number="10">          <span class="kw">else</span> <span class="kw">do</span> cs <span class="ot">&lt;-</span> lazyRead</a>
<a class="sourceLine" id="cb10-11" data-line-number="11">                  return (<span class="dt">Chunk</span> c cs)</a></code></pre></div>
<p><a href="http://hackage.haskell.org/package/hw-prim-0.6.2.17/docs/HaskellWorks-Data-ByteString-Lazy.html#v:hGetContentsChunkedBy"><code>hGetContentsChunkedBy</code></a>, a different version of the function which guarantees that every chunk is the same size (except the last) can be implemented by using <a href="http://hackage.haskell.org/package/base-4.11.1.0/docs/System-IO.html#v:hGetBuf"><code>hGetBuf</code></a> and <a href="http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/src/Data.ByteString.Internal.html#createAndTrim"><code>createAndTrim</code></a> instead of <a href="http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/src/Data.ByteString.html#hGetSome"><code>hGetSome</code></a> and keeping everything else the same:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="ot">hGetContentsChunkedBy ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">IO</span><span class="fu">.</span><span class="dt">Handle</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">LBS.ByteString</span></a>
<a class="sourceLine" id="cb11-2" data-line-number="2">hGetContentsChunkedBy k h <span class="fu">=</span> lazyRead</a>
<a class="sourceLine" id="cb11-3" data-line-number="3">  <span class="kw">where</span> lazyRead <span class="fu">=</span> <span class="dt">IO</span><span class="fu">.</span>unsafeInterleaveIO loop</a>
<a class="sourceLine" id="cb11-4" data-line-number="4">        loop <span class="fu">=</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb11-5" data-line-number="5">            c <span class="ot">&lt;-</span> BS.createAndTrim k <span class="fu">$</span> \p <span class="ot">-&gt;</span> <span class="dt">IO</span><span class="fu">.</span>hGetBuf h p k</a>
<a class="sourceLine" id="cb11-6" data-line-number="6">            <span class="kw">if</span> BS.null c</a>
<a class="sourceLine" id="cb11-7" data-line-number="7">              <span class="kw">then</span> <span class="dt">IO</span><span class="fu">.</span>hClose h <span class="fu">&gt;&gt;</span> return <span class="dt">LBS.Empty</span></a>
<a class="sourceLine" id="cb11-8" data-line-number="8">              <span class="kw">else</span> <span class="dt">LBS.Chunk</span> c <span class="fu">&lt;$&gt;</span> lazyRead</a></code></pre></div>
<p>Benchmarking this shows the performance is comparable to resegmenting.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb12-1" data-line-number="1">$ <span class="kw">for</span> <span class="ex">x</span> in <span class="dt">{1..5}</span><span class="kw">;</span> <span class="kw">do</span> <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="kw">|</span> <span class="ex">hw-simd</span> cat -i - -o - -m default <span class="op">&gt;</span> /dev/null<span class="kw">;</span> <span class="kw">done</span></a>
<a class="sourceLine" id="cb12-2" data-line-number="2"><span class="ex">7.08GiB</span> 0:00:06 [1.10GiB/s]</a>
<a class="sourceLine" id="cb12-3" data-line-number="3"><span class="ex">7.08GiB</span> 0:00:05 [1.26GiB/s]</a>
<a class="sourceLine" id="cb12-4" data-line-number="4"><span class="ex">7.08GiB</span> 0:00:05 [1.29GiB/s]</a>
<a class="sourceLine" id="cb12-5" data-line-number="5"><span class="ex">7.08GiB</span> 0:00:05 [1.27GiB/s]</a>
<a class="sourceLine" id="cb12-6" data-line-number="6"><span class="ex">7.08GiB</span> 0:00:05 [1.27GiB/s]</a>
<a class="sourceLine" id="cb12-7" data-line-number="7">$ <span class="kw">for</span> <span class="ex">x</span> in <span class="dt">{1..5}</span><span class="kw">;</span> <span class="kw">do</span> <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="kw">|</span> <span class="ex">hw-simd</span> cat -i - -o - -m prechunk -c 32704 <span class="op">&gt;</span> /dev/null<span class="kw">;</span> <span class="kw">done</span></a>
<a class="sourceLine" id="cb12-8" data-line-number="8"><span class="ex">7.08GiB</span> 0:00:06 [1.12GiB/s]</a>
<a class="sourceLine" id="cb12-9" data-line-number="9"><span class="ex">7.08GiB</span> 0:00:06 [1.16GiB/s]</a>
<a class="sourceLine" id="cb12-10" data-line-number="10"><span class="ex">7.08GiB</span> 0:00:06 [1.10GiB/s]</a>
<a class="sourceLine" id="cb12-11" data-line-number="11"><span class="ex">7.08GiB</span> 0:00:06 [1.13GiB/s]</a>
<a class="sourceLine" id="cb12-12" data-line-number="12"><span class="ex">7.08GiB</span> 0:00:06 [1.14GiB/s]</a>
<a class="sourceLine" id="cb12-13" data-line-number="13">$ <span class="kw">for</span> <span class="ex">x</span> in <span class="dt">{1..5}</span><span class="kw">;</span> <span class="kw">do</span> <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="kw">|</span> <span class="ex">hw-simd</span> cat -i - -o - -m resegment -c 64 <span class="op">&gt;</span> /dev/null<span class="kw">;</span> <span class="kw">done</span></a>
<a class="sourceLine" id="cb12-14" data-line-number="14"><span class="ex">7.08GiB</span> 0:00:06 [1.14GiB/s]</a>
<a class="sourceLine" id="cb12-15" data-line-number="15"><span class="ex">7.08GiB</span> 0:00:06 [1.16GiB/s]</a>
<a class="sourceLine" id="cb12-16" data-line-number="16"><span class="ex">7.08GiB</span> 0:00:06 [1.06GiB/s]</a>
<a class="sourceLine" id="cb12-17" data-line-number="17"><span class="ex">7.08GiB</span> 0:00:05 [1.18GiB/s]</a>
<a class="sourceLine" id="cb12-18" data-line-number="18"><span class="ex">7.08GiB</span> 0:00:05 [1.19GiB/s]</a></code></pre></div>
<p>This is likely because the chunks returned by <code>hGetContents</code> were already large enough that the extra effort to resegment the lazy bytestring is negligible.</p>
<h1 id="closing-remarks">Closing Remarks</h1>
<p>This post looked at how we can resegment our lazy bytestring to make the chunk sizes compatible with SIMD instructions at a reasonable cost.</p>
<p>The next post will look at using FFI to call into C functions that use SIMD to do the heavy lifting.</p>]]></summary>
</entry>
<entry>
    <title>Introduction to SIMD with linecount</title>
    <link href="https://haskell-works.github.io/posts/2018-09-03-simd-with-linecount.html" />
    <id>https://haskell-works.github.io/posts/2018-09-03-simd-with-linecount.html</id>
    <published>2018-09-03T00:00:00Z</published>
    <updated>2018-09-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In a <a href="../posts/2018-08-08-data-parallel-rank-select-bit-string-construction.html">previous post</a> I talked about using broadword techniques to create a rank-select bit-string from text.</p>
<p>This post will explore using Single Instruction, Multiple Data (SIMD) instructions to achieve the same thing.</p>
<p>The exploration will benchmark the SIMD, broadword and naive implementations of line count to illustrate why SIMD instructions are important to improving parsing performance.</p>
<h1 id="creating-a-rank-select-bit-string-with-simd">Creating a rank-select bit-string with SIMD</h1>
<p>Recall from the earlier post that we can build a rank-select bit-string from a piece of text like this:</p>
<pre class="text"><code>&quot;name&quot;,&quot;age&quot;,&quot;profession&quot;␤John,30,Code Monkey␤Kyle,40,Data Scrubber
0000000000000000000000000100000000000000000001000000000000000000000</code></pre>
<p>Here, I mark every bit that corresponds to a newline character at the corresponding position in the text.</p>
<p>From this bit-string, we can use the <code>popCount</code> operation to add up the number of 1-bits in the string to arrive at the line count for our text.</p>
<p>Recall that we were able to use broadword programming techniques to do this conversion:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="ot">testWord8s ::</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">testWord8s w <span class="fu">=</span>  <span class="kw">let</span> w8s <span class="fu">=</span> w</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">                    w4s <span class="fu">=</span> w8s <span class="fu">.|.</span> (w8s <span class="fu">.&gt;.</span> <span class="dv">4</span>)</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">                    w2s <span class="fu">=</span> w4s <span class="fu">.|.</span> (w4s <span class="fu">.&gt;.</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">                    w1s <span class="fu">=</span> w2s <span class="fu">.|.</span> (w2s <span class="fu">.&gt;.</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb2-6" data-line-number="6">                <span class="kw">in</span>  pext w1s <span class="bn">0x0101010101010101</span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="ot">{-# INLINE testWord8s #-}</span></a></code></pre></div>
<p>This approach allowed us to process 8 bytes at a time at the cost of three OR <code>(.|.)</code>, three SHIFT <code>(.&gt;.)</code> and one <code>pext</code> operations, all of which are very cheap.</p>
<p>Whilst, broadword techniques allowed us to do this 8 bytes at a time, SIMD instructions that exist on some generations of CPUs can help us build our rank-select bit-string in a way that lets us process 16, 32 or even 64-bytes at a time.</p>
<p>On my Macbook, I can run a command to determine what the features my CPU has:</p>
<pre><code>$ sysctl -a | grep cpu | grep features:
machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C
machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 HLE AVX2 BMI2 INVPCID RTM SMAP RDSEED ADX IPT SGX FPU_CSDS MPX CLFSOPT
machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI</code></pre>
<p>From this list, I know that my CPU supports the AVX2 instruction set which makes available CPU intrinsics such as <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=765,767,802,766&amp;text=_mm256_cmpeq_epi8"><code>_mm256_cmpeq_epi8</code></a> asn <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=765,767,802,766,3612&amp;text=_mm256_movemask_epi8"><code>_mm256_movemask_epi8</code></a>.</p>
<p>With 256-bit registers, we’re in a position to improve our parallelism from 8 to 32 bytes at a time.</p>
<p>Now let’s starting indexing out text.</p>
<p>In C, we first need to initialise a SIMD register to contain 32 copies of our delimiter byte (in this case newline characters):</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode c"><code class="sourceCode c"><a class="sourceLine" id="cb4-1" data-line-number="1">__m256i ws_newline = broadcast_u8((<span class="dt">uint8_t</span>)<span class="ch">&#39;\n&#39;</span>);</a></code></pre></div>
<p>then we loop over the bytes 32-bytes at a time and perform a parallel comparison on each chunk:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode c"><code class="sourceCode c"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="dt">char</span> *text          = ...; <span class="co">// The text to parse</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="dt">size_t</span> text_length  = ...; <span class="co">// The length of the text to parse</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="dt">uint32_t</span> *target    = ...; <span class="co">// The buffer for the rank-select bit-string we are building</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"></a>
<a class="sourceLine" id="cb5-5" data-line-number="5"><span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i != bytes_end; i += <span class="dv">32</span>) {</a>
<a class="sourceLine" id="cb5-6" data-line-number="6">  __m256i matches_bytes = _mm256_cmpeq_epi8(*(__m256i*)(text + i), ws_newlines);</a>
<a class="sourceLine" id="cb5-7" data-line-number="7"></a>
<a class="sourceLine" id="cb5-8" data-line-number="8">  <span class="dt">int</span> matches_bits = _mm256_movemask_epi8(matches_bytes[<span class="dv">3</span>]);</a>
<a class="sourceLine" id="cb5-9" data-line-number="9"></a>
<a class="sourceLine" id="cb5-10" data-line-number="10">  target[i / <span class="dv">32</span>] = (<span class="dt">uint32_t</span>)matches_bits;</a>
<a class="sourceLine" id="cb5-11" data-line-number="11">}</a></code></pre></div>
<p>The above code compares each byte in <code>ws_newlines</code> with the corresponding byte in <code>(__m256i*)text</code>.</p>
<p><code>matches_bytes</code> will contain 32 bytes, each of which will hold one of two values: <code>0x00</code> or <code>0xff</code> dependending on whether the corresponding byte in <code>(__m256i*)text</code> was equal to the corresponding by in <code>matches_bytes</code>.</p>
<p>The <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=765,767,802,766,3612&amp;text=_mm256_movemask_epi8"><code>_mm256_movemask_epi8</code></a> function is then used to compress this result by taking the high bit of each byte in <code>matches_bytes</code> and packing them into <code>matches_bits</code>.</p>
<p>Compared to the broadword implementation, this reduces the number of load/stores by a factor of 8 and the number of register instructions for a 32-byte chunk from 56 to 2.</p>
<h1 id="benchmarking">Benchmarking</h1>
<p>To look at the potential performance gains from using SIMD versus other alternatives, I’ve written three versions of a tool that counts the number of lines in a text file: <code>naive</code>, <code>broadword</code> and <code>simd</code></p>
<h2 id="naive">Naive</h2>
<p>The naive version does nothing more than traverse the text byte-by-byte and compare each byte for equality and incrementing a count on success:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode c"><code class="sourceCode c"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="dt">size_t</span> process_data(<span class="dt">char</span> *text, <span class="dt">size_t</span> bytes_read)</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">{</a>
<a class="sourceLine" id="cb6-3" data-line-number="3">  <span class="dt">size_t</span> popCount = <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb6-4" data-line-number="4"></a>
<a class="sourceLine" id="cb6-5" data-line-number="5">  <span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; bytes_read; ++i)</a>
<a class="sourceLine" id="cb6-6" data-line-number="6">  {</a>
<a class="sourceLine" id="cb6-7" data-line-number="7">    <span class="cf">if</span> (text[i] == <span class="ch">&#39;\n&#39;</span>) {</a>
<a class="sourceLine" id="cb6-8" data-line-number="8">      ++popCount;</a>
<a class="sourceLine" id="cb6-9" data-line-number="9">    }</a>
<a class="sourceLine" id="cb6-10" data-line-number="10">  }</a>
<a class="sourceLine" id="cb6-11" data-line-number="11"></a>
<a class="sourceLine" id="cb6-12" data-line-number="12">  <span class="cf">return</span> popCount;</a>
<a class="sourceLine" id="cb6-13" data-line-number="13">}</a></code></pre></div>
<h2 id="broadword">Broadword</h2>
<p>The broadword version uses the XOR operation to perform parallel comparison of all 8 bytes in the word with one instruction and relies on a small number of SHIFTS (<code>&gt;&gt;</code>) and ANDS (<code>&amp;</code>) to convert the result into the bit-string we need:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode c"><code class="sourceCode c"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="dt">size_t</span> process_data(<span class="dt">char</span> *text, <span class="dt">size_t</span> bytes_read)</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">{</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">  <span class="dt">size_t</span> popCount = <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb7-4" data-line-number="4">  <span class="dt">char</span> *mask = <span class="st">&quot;</span><span class="sc">\n\n\n\n\n\n\n\n</span><span class="st">&quot;</span>;</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">  <span class="dt">uint64_t</span> wm = *(<span class="dt">uint64_t</span> *)mask;</a>
<a class="sourceLine" id="cb7-6" data-line-number="6"></a>
<a class="sourceLine" id="cb7-7" data-line-number="7">  <span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; bytes_read; i += <span class="dv">8</span>) {</a>
<a class="sourceLine" id="cb7-8" data-line-number="8">    <span class="cf">if</span> (i + <span class="dv">8</span> &lt;= bytes_read) {</a>
<a class="sourceLine" id="cb7-9" data-line-number="9">      <span class="dt">uint64_t</span> w0 = ~(*(<span class="dt">uint64_t</span> *)(text + i) ^ wm);</a>
<a class="sourceLine" id="cb7-10" data-line-number="10">      <span class="dt">uint64_t</span> w1 = (w0 &gt;&gt; <span class="dv">4</span>) &amp; w0; <span class="co">// Not a typo.  See De Morgan&#39;s law.</span></a>
<a class="sourceLine" id="cb7-11" data-line-number="11">      <span class="dt">uint64_t</span> w2 = (w1 &gt;&gt; <span class="dv">2</span>) &amp; w1;</a>
<a class="sourceLine" id="cb7-12" data-line-number="12">      <span class="dt">uint64_t</span> w3 = (w2 &gt;&gt; <span class="dv">1</span>) &amp; w2;</a>
<a class="sourceLine" id="cb7-13" data-line-number="13"></a>
<a class="sourceLine" id="cb7-14" data-line-number="14">      <span class="dt">uint64_t</span> bits = (<span class="dt">uint64_t</span>)_pext_u64(w3, 0x0101010101010101L);</a>
<a class="sourceLine" id="cb7-15" data-line-number="15"></a>
<a class="sourceLine" id="cb7-16" data-line-number="16">      popCount += _popcnt64(bits);</a>
<a class="sourceLine" id="cb7-17" data-line-number="17">    } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb7-18" data-line-number="18">      <span class="cf">for</span> (<span class="dt">size_t</span> j = i; j &lt; bytes_read; ++j) {</a>
<a class="sourceLine" id="cb7-19" data-line-number="19">        <span class="cf">if</span> (text[j] == <span class="ch">&#39;\n&#39;</span>) {</a>
<a class="sourceLine" id="cb7-20" data-line-number="20">          ++popCount;</a>
<a class="sourceLine" id="cb7-21" data-line-number="21">        }</a>
<a class="sourceLine" id="cb7-22" data-line-number="22">      }</a>
<a class="sourceLine" id="cb7-23" data-line-number="23">    }</a>
<a class="sourceLine" id="cb7-24" data-line-number="24">  }</a>
<a class="sourceLine" id="cb7-25" data-line-number="25"></a>
<a class="sourceLine" id="cb7-26" data-line-number="26">  <span class="cf">return</span> popCount;</a>
<a class="sourceLine" id="cb7-27" data-line-number="27">}</a></code></pre></div>
<p>The function falls back to byte-by-byte comparison if there are any bytes left that cannot fill a 64-bit word.</p>
<h2 id="simd">SIMD</h2>
<p>The SIMD version requires a register to be initialised with the our delimiter replicated to all bytes of the SIMD register in the <code>ws_newlines</code> argument with the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=765,767,802,4676&amp;text=_mm256_set1_epi8"><code>_mm256_set1_epi8</code></a> intrinsic.</p>
<p>This value is then compared to the text 64-bytes at a time with the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=765,767,802,766&amp;text=_mm256_cmpeq_epi8"><code>_mm256_cmpeq_epi8</code></a> intrinsic and summarised into a bit-string with the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=765,767,802,766,3612&amp;text=_mm256_movemask_epi8"><code>_mm256_movemask_epi8</code></a> intrinsic.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode c"><code class="sourceCode c"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="dt">size_t</span> process_data(<span class="dt">char</span> *text, <span class="dt">size_t</span> bytes_read)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">{</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">  __m256i ws_newlines = _mm256_set1_epi8(<span class="ch">&#39;\n&#39;</span>);</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">  <span class="dt">char</span> *bytes_end = text + bytes_read;</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">  <span class="dt">size_t</span> popCount = <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb8-6" data-line-number="6"></a>
<a class="sourceLine" id="cb8-7" data-line-number="7">  <span class="cf">if</span> ((bytes_read &amp; <span class="bn">0x1f</span>) == <span class="dv">0</span>) {</a>
<a class="sourceLine" id="cb8-8" data-line-number="8">    <span class="cf">for</span> (; text != bytes_end; text += <span class="dv">32</span>) {</a>
<a class="sourceLine" id="cb8-9" data-line-number="9">      __m256i matches_bytes = _mm256_cmpeq_epi8(*(__m256i*)text, ws_newlines);</a>
<a class="sourceLine" id="cb8-10" data-line-number="10"></a>
<a class="sourceLine" id="cb8-11" data-line-number="11">      <span class="dt">int</span> matches_bits = _mm256_movemask_epi8(matches_bytes);</a>
<a class="sourceLine" id="cb8-12" data-line-number="12"></a>
<a class="sourceLine" id="cb8-13" data-line-number="13">      popCount += _mm_popcnt_u32((<span class="dt">uint32_t</span>)matches_bits);</a>
<a class="sourceLine" id="cb8-14" data-line-number="14">    }</a>
<a class="sourceLine" id="cb8-15" data-line-number="15">  } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb8-16" data-line-number="16">    <span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; bytes_read; i += <span class="dv">32</span>) {</a>
<a class="sourceLine" id="cb8-17" data-line-number="17">      <span class="dt">size_t</span> bytes_read_iter = bytes_read - i;</a>
<a class="sourceLine" id="cb8-18" data-line-number="18"></a>
<a class="sourceLine" id="cb8-19" data-line-number="19">      <span class="cf">if</span> (bytes_read_iter &gt; <span class="dv">32</span>) {</a>
<a class="sourceLine" id="cb8-20" data-line-number="20">        bytes_read_iter = <span class="dv">32</span>;</a>
<a class="sourceLine" id="cb8-21" data-line-number="21">      }</a>
<a class="sourceLine" id="cb8-22" data-line-number="22"></a>
<a class="sourceLine" id="cb8-23" data-line-number="23">      __m256i matches_bytes = _mm256_cmpeq_epi8(*(__m256i*)(text + i), ws_newlines);</a>
<a class="sourceLine" id="cb8-24" data-line-number="24"></a>
<a class="sourceLine" id="cb8-25" data-line-number="25">      <span class="dt">int</span> matches_bits = _mm256_movemask_epi8(matches_bytes);</a>
<a class="sourceLine" id="cb8-26" data-line-number="26"></a>
<a class="sourceLine" id="cb8-27" data-line-number="27">      popCount += _mm_popcnt_u32((<span class="dt">uint32_t</span>)((<span class="bn">0xffffffff</span> &gt;&gt; (<span class="dv">32</span> - bytes_read_iter)) &amp; (<span class="dt">uint32_t</span>)matches_bits));</a>
<a class="sourceLine" id="cb8-28" data-line-number="28">    }</a>
<a class="sourceLine" id="cb8-29" data-line-number="29">  }</a>
<a class="sourceLine" id="cb8-30" data-line-number="30"></a>
<a class="sourceLine" id="cb8-31" data-line-number="31">  <span class="cf">return</span> popCount;</a>
<a class="sourceLine" id="cb8-32" data-line-number="32">}</a></code></pre></div>
<p>The function falls back to byte-by-byte comparison if there are any bytes left that cannot fill a 256-bit SIMD register.</p>
<h1 id="initial-benchmark-results">Initial benchmark results</h1>
<p>I benchmark the three versions of the code in C as well as <code>wc -l</code> as a baseline.</p>
<p>The source code for the benchmarks can be found <a href="https://github.com/haskell-works/blog-examples/tree/3f65f1d6c4dac274e57b9ddcf4c610d321fb3234/linecount">here</a> and the results <a href="https://github.com/haskell-works/blog-examples/commit/3f65f1d6c4dac274e57b9ddcf4c610d321fb3234">here</a>.</p>
<p>The code is compiled with <code>-mavx2 -mbmi2</code> to enable access to the SIMD and bit manipulation instructions I need.</p>
<pre class="text"><code>wc -l                   0m5.458s
./naive.auto.out        0m2.654s
./broadword.auto.out    0m2.963s
./simd.auto.out         0m1.759s</code></pre>
<p>I find that <code>wc -l</code> is the slowest and the <code>simd</code> implementation the fastest and the broadword implementation performs somewhere in between.</p>
<p>That much is as expected.</p>
<p>The surprise here is that the naive version runs faster than the broadword version.</p>
<p>What is going on here?</p>
<p>Before jumping to conclusions, let’s take a look at the assembly code generated for the naive version:</p>
<pre class="text"><code>_process_data:                          ## @process_data
    .cfi_startproc
...
## BB#8:
    leaq            -1(%r8), %rdx
    subq            %rax, %rdx
    vpxor           %ymm8, %ymm8, %ymm8
    xorl            %eax, %eax
    vpbroadcastd    LCPI0_0(%rip), %xmm4 ## xmm4 = [10,10,10,10]
    vpbroadcastq    LCPI0_1(%rip), %ymm5 ## ymm5 = [1,1,1,1]
    vpxor           %ymm9, %ymm9, %ymm9
    vpxor           %ymm2, %ymm2, %ymm2
    vpxor           %ymm3, %ymm3, %ymm3
    .p2align 4, 0x90
...
    .cfi_endproc</code></pre>
<p>If we lookup the Intel documentation for the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=765,767,802,534&amp;text=vpbroadcastq"><code>vpbroadcastq</code></a> and <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=765,767,802,534,5724&amp;text=vpxor"><code>vpxor</code></a> instructions we find that these functions are SIMD instructions and that <code>gcc</code> has auto-vectorised the naive implementation.</p>
<p>The naive implementation was in fact elaborately auto-vectorised that a 14 line C function became 152 lines of assembly code.</p>
<p>If we deny <code>gcc</code> the freedom to auto-vectorise the code with the <code>-fno-tree-vectorize</code> flag we get <code>71</code> lines of assembly instead and suffer worse results by far:</p>
<pre class="text"><code>./naive.out           0m4.659s
./broadword.out       0m2.960s
./simd.out            0m1.703s
wc -l                 0m5.458s</code></pre>
<p>GHC currently does not perform any auto-vectorisation, so I’d expected the naive version when written in Haskell would perform no better than the naive C implementation without auto-vectorsation.</p>
<h1 id="closing-remarks">Closing remarks</h1>
<p>The benchmarks make a compelling case for using SIMD instructions where ever possible and broadword where the target CPU architecture does not support the SIMD instructions we need.</p>
<p>Unfortunately, GHC does not have native support for the SIMD instructions we need.</p>
<p>In a future post I’ll look at using these SIMD from GHC using Foreign Function Interface (FFI) and addressing some of the challenges of using SIMD with Haskell’s lazy IO.</p>]]></summary>
</entry>
<entry>
    <title>Bit-manipulation operations for high-performance succinct data-structures and CSV parsing</title>
    <link href="https://haskell-works.github.io/posts/2018-08-22-pdep-and-pext-bit-manipulation-functions.html" />
    <id>https://haskell-works.github.io/posts/2018-08-22-pdep-and-pext-bit-manipulation-functions.html</id>
    <published>2018-08-22T00:00:00Z</published>
    <updated>2018-08-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In last week’s <a href="../posts/2018-08-08-data-parallel-rank-select-bit-string-construction.html">post</a> I described how to produce rank-select bit-strings for an RFC-compliant CSV format without detailing how to perform efficiently the operation that splits odd and even bits of a bit-string into separate bit-strings.</p>
<p>In an earlier <a href="../posts/2018-08-01-introduction-to-rank-select-bit-string.html">post</a> I discussed <code>rank</code> and <code>select</code> operations, but also omitted to describe how they can be implemented efficiently.</p>
<p>In this blog post I will properly introduce the <code>popcnt</code>, <code>pext</code>, <code>tzcnt</code> and <code>pdep</code> operations and how they relate to the performance of our conceptual succinct data-structure based CSV parser.</p>
<h1 id="bit-manipulation-instructions">Bit-manipulation instructions</h1>
<h1 id="pop-count">Pop Count</h1>
<p>The <code>popcnt</code> operation is quite straight-forward. It takes an integer as its input argument, counts the number of 1-bits and produces an integer containing the count.</p>
<p>In the following example, I count the number of 1-bits in my bit-string and find there are 5:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="fu">~/</span>wrk<span class="fu">/</span>haskell<span class="fu">-</span>works<span class="fu">/</span>hw<span class="fu">-</span>rankselect<span class="fu">-</span>base <span class="fu">$</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="fu">$</span> stack repl</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">λ<span class="fu">&gt;</span> <span class="kw">import</span> <span class="dt">Data.Word</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4">λ<span class="fu">&gt;</span> <span class="kw">let</span> bs <span class="fu">=</span> fromJust <span class="fu">$</span> bitRead <span class="st">&quot;01110101&quot;</span><span class="ot"> ::</span> <span class="dt">Word8</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5">λ<span class="fu">&gt;</span> popCount1 bs</a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="dv">5</span></a></code></pre></div>
<h1 id="trailing-zeros-count">Trailing Zeros Count</h1>
<p>The <code>tzcnt</code> operation is also quite straight-forward. It counts the number of “trailing zeros” in the bit-string.</p>
<p>Unfortunately, because we are on the topic of succinct data-structures, all our bits are expressed in Little-Endian, so visually we are looking at the leading zeros.</p>
<p>In the following example, I count the number of trailing zeros in my bit-string and find there are 3 (as indicated by the <code>***</code> annotation):</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="fu">~/</span>wrk<span class="fu">/</span>haskell<span class="fu">-</span>works<span class="fu">/</span>hw<span class="fu">-</span>rankselect<span class="fu">-</span>base <span class="fu">$</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="fu">$</span> stack repl</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">λ<span class="fu">&gt;</span> <span class="kw">import</span> <span class="dt">Data.Word</span>             ***</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">λ<span class="fu">&gt;</span> <span class="kw">let</span> bs <span class="fu">=</span> fromJust <span class="fu">$</span> bitRead <span class="st">&quot;00010101&quot;</span><span class="ot"> ::</span> <span class="dt">Word8</span></a>
<a class="sourceLine" id="cb2-5" data-line-number="5">λ<span class="fu">&gt;</span> countTrailingZeros bs</a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="dv">3</span></a></code></pre></div>
<h1 id="parallel-extract">Parallel Extract</h1>
<p>The <code>pext</code> or “parallel extract” operation , is an operation that takes a bit-mask and extracts the bits from the <code>source</code> word corresponding to 1-bits in the bit-mask and packs them into least-significant side of the word.</p>
<pre class="text"><code>* All words in Little-Endian *

mask   0011001100110011
source 0110101110101001
bits     10  11  10  01
       ┌─┘│  ││  ││  ││
       │┌─┘  ││  ││  ││
       ││┌───┘│  ││  ││
       │││┌───┘  ││  ││
       ││││┌─────┘│  ││
       │││││┌─────┘  ││
       ││││││┌───────┘│
       │││││││┌───────┘
result 1011100100000000</code></pre>
<p>In the following example, I extract the high nibble of each byte in my <code>Word32</code> by using a mask where all the high-nibble bits are set to <code>1</code>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="fu">~/</span>wrk<span class="fu">/</span>haskell<span class="fu">-</span>works<span class="fu">/</span>hw<span class="fu">-</span>rankselect<span class="fu">-</span>base <span class="fu">$</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="fu">$</span> stack repl</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">λ<span class="fu">&gt;</span> <span class="kw">import</span> <span class="dt">Data.Word</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4">λ<span class="fu">&gt;</span> <span class="kw">import</span> <span class="dt">Data.Bits.Pext</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5">λ<span class="fu">&gt;</span> <span class="kw">let</span> source <span class="fu">=</span> fromJust <span class="fu">$</span> bitRead <span class="st">&quot;01110101 11001010 00001001 01011000&quot;</span><span class="ot"> ::</span> <span class="dt">Word32</span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6">λ<span class="fu">&gt;</span> <span class="kw">let</span> mask   <span class="fu">=</span> fromJust <span class="fu">$</span> bitRead <span class="st">&quot;00001111 00001111 00001111 00001111&quot;</span><span class="ot"> ::</span> <span class="dt">Word32</span></a>
<a class="sourceLine" id="cb4-7" data-line-number="7">λ<span class="fu">&gt;</span> bitShow <span class="fu">$</span> pext source mask</a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="st">&quot;01011010 10011000 00000000 00000000&quot;</span></a></code></pre></div>
<h1 id="parallel-deposit">Parallel Deposit</h1>
<p>The <code>pdep</code> or “parallel deposit” operation, is an operation that takes a bit-mask and deposits the least-significant n-bits from the <code>source</code> word where <code>n</code> is the number of bits in the bit-mask and deposits them at the positions marked by 1-bits in the bit-mask.</p>
<pre class="text"><code>* All words in Little-Endian *

mask   0011001100110011
source 1011100100000000
       │││││││└───────┐
       ││││││└───────┐│
       │││││└─────┐  ││
       ││││└─────┐│  ││
       │││└───┐  ││  ││
       ││└───┐│  ││  ││
       │└─┐  ││  ││  ││
       └─┐│  ││  ││  ││
bits     10  11  10  01
bits   0010001100100001</code></pre>
<p>In the following example, I deposit the first eight bits in my bits-string into the high nibble of each byte in my <code>Word32</code>, again by using a mask where all the high-nibble bits are set to <code>1</code>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="fu">~/</span>wrk<span class="fu">/</span>haskell<span class="fu">-</span>works<span class="fu">/</span>hw<span class="fu">-</span>rankselect<span class="fu">-</span>base <span class="fu">$</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="fu">$</span> stack repl</a>
<a class="sourceLine" id="cb6-3" data-line-number="3">λ<span class="fu">&gt;</span> <span class="kw">import</span> <span class="dt">Data.Word</span></a>
<a class="sourceLine" id="cb6-4" data-line-number="4">λ<span class="fu">&gt;</span> <span class="kw">import</span> <span class="dt">Data.Bits.Pdep</span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5">λ<span class="fu">&gt;</span> <span class="kw">let</span> source <span class="fu">=</span> fromJust <span class="fu">$</span> bitRead <span class="st">&quot;01011010 10011000 00000000 00000000&quot;</span><span class="ot"> ::</span> <span class="dt">Word32</span></a>
<a class="sourceLine" id="cb6-6" data-line-number="6">λ<span class="fu">&gt;</span> <span class="kw">let</span> mask   <span class="fu">=</span> fromJust <span class="fu">$</span> bitRead <span class="st">&quot;00001111 00001111 00001111 00001111&quot;</span><span class="ot"> ::</span> <span class="dt">Word32</span></a>
<a class="sourceLine" id="cb6-7" data-line-number="7">λ<span class="fu">&gt;</span> bitShow <span class="fu">$</span> pdep source mask</a>
<a class="sourceLine" id="cb6-8" data-line-number="8"><span class="st">&quot;00000101 00001010 00001001 00001000&quot;</span></a></code></pre></div>
<h1 id="availability-on-ghc">Availability on GHC</h1>
<p>In Haskell, the <code>popCount</code> operation is available via the <a href="http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Bits.html#v:popCount"><code>popCount</code></a> function in <code>Data.Bits</code> module of the <a href="http://hackage.haskell.org/package/base">base</a> package.</p>
<p>On most modern x86 systems, the <code>popCount</code> operation is available on 64-bit integers in the form of the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=765,767,802,4093&amp;text=popcnt"><code>POPCNT</code></a> CPU instruction, so it is very fast.</p>
<p>It is also available to C programs by way of the <code>_popcnt64</code> CPU intrinsic, but what about Haskell?</p>
<p>To confirm that the function does in fact compile down to an instruction we first check the <a href="https://github.com/ghc/ghc/blob/8df24474d0194d28b8273c1539af05793156e23f/libraries/base/Data/Bits.hs#L508">definition</a> here.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb7-1" data-line-number="1">popCount (<span class="dt">W</span><span class="fu">#</span> x<span class="fu">#</span>)         <span class="fu">=</span> <span class="dt">I</span><span class="fu">#</span> (word2Int<span class="fu">#</span> (popCnt<span class="fu">#</span> x<span class="fu">#</span>))</a></code></pre></div>
<p>and notice the use of the primop <code>popCnt#</code>.</p>
<p>Digging further into the <a href="https://github.com/ghc/ghc/blob/ab55b4ddb717dab13d8b4900024ccbc8e9280c5c/compiler/nativeGen/X86/CodeGen.hs#L1861">GHC source code</a>:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb8-1" data-line-number="1">    sse4_2 <span class="ot">&lt;-</span> sse4_2Enabled</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">    <span class="kw">let</span> platform <span class="fu">=</span> targetPlatform dflags</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">    <span class="kw">if</span> sse4_2</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">      <span class="kw">then</span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5">                      <span class="fu">....</span></a>
<a class="sourceLine" id="cb8-6" data-line-number="6">          unitOL (<span class="dt">MOVZxL</span> <span class="dt">II8</span> (<span class="dt">OpReg</span> src_r) (<span class="dt">OpReg</span> src_r)) <span class="ot">`appOL`</span></a>
<a class="sourceLine" id="cb8-7" data-line-number="7">          unitOL (<span class="dt">POPCNT</span> <span class="dt">II16</span> (<span class="dt">OpReg</span> src_r) dst_r)</a></code></pre></div>
<p>We find that this primop generates the <code>POPCNT</code> instruction provided that <code>sse4_2Enabled</code> yields <code>True</code>, which according to the <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using.html#platform-specific-flags">GHC User Guide</a> can be switched on with the <code>-msse4.2</code> <code>ghc</code> flag since GHC 7.4.1 on x86 CPU architectures.</p>
<p>A similar search can be done for the <code>tzcnt</code> operation, but <a href="https://github.com/ghc/ghc/blob/44ba66527ae207ce2dd64eb2bce14656d474f6d1/compiler/nativeGen/X86/CodeGen.hs#L1990">unfortunately the equivalent primop expands to a whole bunch of instructions</a>:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb9-1" data-line-number="1">([ <span class="dt">MOV</span>      <span class="dt">II32</span> (<span class="dt">OpReg</span> rhi)         (<span class="dt">OpReg</span> tmp_r)</a>
<a class="sourceLine" id="cb9-2" data-line-number="2"> , <span class="dt">OR</span>       <span class="dt">II32</span> (<span class="dt">OpReg</span> rlo)         (<span class="dt">OpReg</span> tmp_r)</a>
<a class="sourceLine" id="cb9-3" data-line-number="3"> , <span class="dt">MOV</span>      <span class="dt">II32</span> (<span class="dt">OpImm</span> (<span class="dt">ImmInt</span> <span class="dv">64</span>)) (<span class="dt">OpReg</span> dst_r)</a>
<a class="sourceLine" id="cb9-4" data-line-number="4"> , <span class="dt">JXX</span> <span class="dt">EQQ</span>    lbl2</a>
<a class="sourceLine" id="cb9-5" data-line-number="5"> , <span class="dt">JXX</span> <span class="dt">ALWAYS</span> lbl1</a>
<a class="sourceLine" id="cb9-6" data-line-number="6"> </a>
<a class="sourceLine" id="cb9-7" data-line-number="7"> , <span class="dt">NEWBLOCK</span>   lbl1</a>
<a class="sourceLine" id="cb9-8" data-line-number="8"> , <span class="dt">BSF</span>     <span class="dt">II32</span> (<span class="dt">OpReg</span> rhi)         dst_r</a>
<a class="sourceLine" id="cb9-9" data-line-number="9"> , <span class="dt">ADD</span>     <span class="dt">II32</span> (<span class="dt">OpImm</span> (<span class="dt">ImmInt</span> <span class="dv">32</span>)) (<span class="dt">OpReg</span> dst_r)</a>
<a class="sourceLine" id="cb9-10" data-line-number="10"> , <span class="dt">BSF</span>     <span class="dt">II32</span> (<span class="dt">OpReg</span> rlo)         tmp_r</a>
<a class="sourceLine" id="cb9-11" data-line-number="11"> , <span class="dt">CMOV</span> <span class="dt">NE</span> <span class="dt">II32</span> (<span class="dt">OpReg</span> tmp_r)       dst_r</a>
<a class="sourceLine" id="cb9-12" data-line-number="12"> , <span class="dt">JXX</span> <span class="dt">ALWAYS</span> lbl2</a>
<a class="sourceLine" id="cb9-13" data-line-number="13"> </a>
<a class="sourceLine" id="cb9-14" data-line-number="14"> , <span class="dt">NEWBLOCK</span>   lbl2</a>
<a class="sourceLine" id="cb9-15" data-line-number="15">])</a></code></pre></div>
<p>The operation is emulated with <code>BSF</code> or Bit-Scan-Forward, which does something similar, but only works on 32-bit integers.</p>
<p>Unfortunately for me, I needed optimised <code>pdep</code> and <code>pext</code> primops from <code>ghc</code> for my succinct data-structure libraries, but sadly they weren’t available at the time I sought them, which was about this time last year.</p>
<p>I created a <a href="https://ghc.haskell.org/trac/ghc/ticket/14206">trac issue</a>, and one thing led to another and I ended up <a href="https://phabricator.haskell.org/D4236">implementing these primops</a> in <code>ghc</code> over the space of several months with the kind help of <a href="https://twitter.com/bgamari">Ben Gamari</a> and <a href="https://twitter.com/angerman_io">Moritz Angermann</a>.</p>
<p>The functionality is not exposed in <code>base</code>, but they can be accessed from the Haskell-Works <a href="https://github.com/haskell-works/bits-extra">bits-extra</a> library. Benchmark results can be found there-in.</p>
<p>If anyone is looking to jump into GHC development, a good first project that can improve the performance of succinct data-structures on Haskell code would be to add native support for <a href="http://hackage.haskell.org/package/ghc-prim-0.5.2.0/docs/src/GHC.Prim.html#ctz64%23"><code>ctz#</code></a> primop in GHC.</p>
<p>GHC needs more contributions and it would be great to see GHC become a better platform for writing high performance code.</p>
<h1 id="applications">Applications</h1>
<h2 id="very-fast-implementation-of-rank-and-select">Very fast implementation of Rank and Select</h2>
<p>About this time last year, <a href="https://twitter.com/kmett">Ed Kmett</a>, sent me very interesting paper on <a href="http://delivery.acm.org/10.1145/3040000/3035963/p775-pandey.pdf?ip=144.132.158.200&amp;id=3035963&amp;acc=CHORUS&amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;__acm__=1534943252_b1faffcd640ba8448fc9c811c1a3b2db">A General-Purpose Counting Filter: Making Every Bit Count</a>.</p>
<figure>
<img src="../images/kmett-quotient-filter.png" alt="Kmett nicely dropping me a paper on Quotient Filters and walking away" /><figcaption>Kmett nicely dropping me a paper on Quotient Filters and walking away</figcaption>
</figure>
<p>To really miss the amazing contribution of the paper and zoom in on the section relevant to this discussion go to section 3.2 “Fast x86 rank and select”, which describes how the <code>PDEP</code> and <code>TZCNT</code> instructions can be used to implement fast rank and select.</p>
<p>The formula for rank is given in the paper as:</p>
<figure>
<img src="../images/x86-rank.png" alt="Rank in terms of Population Count" /><figcaption>Rank in terms of Population Count</figcaption>
</figure>
<p>The <code>rank i</code> of a bit-string is the prefix-sum of the bit-string of the given length <code>i</code>.</p>
<p>The diagram below shows five examples of rank operations on the same bit-string (b).</p>
<p>For the operation <code>rank i</code>, the expression <code>2ⁱ-1</code> computes a bit-mask (a) consisting of a prefix of 1-bits of length <code>i</code> that can be used to zero in our bit-string (b) all the bits beyond the prefix length to produce (c).</p>
<p>A pop count of (c) counts all the 1-bits annotated by <code>*</code> (d) and becomes our rank (e).</p>
<pre class="text"><code>        rank 2            rank 4            rank 6            rank 8            rank 10         
(a)     1100000000000000  1111000000000000  1111110000000000  1111111100000000  1111111111000000
(b)     0100100010011000  0100100010011000  0100100010011000  0100100010011000  0100100010011000
(c)     0100000000000000  0100000000000000  0100100000000000  0100100000000000  0100100010000000
(d)      *                 *                 *  *              *  *              *  *   *       
(e)      1                 1                 2                 2                 3</code></pre>
<figure>
<img src="../images/x86-select.png" alt="Select in terms of Parallel Deposit" /><figcaption>Select in terms of Parallel Deposit</figcaption>
</figure>
<p>The <code>select i</code> of a bit-string is length of the smallest prefix that includes <code>i</code> 1-bits in the bit-string. Unfortunately, I feel like there is an off-by-one error in the formula and that it should actually be:</p>
<blockquote>
<code>select(v, i) = tzcnt(pdep(2</code><sup><code>i-1</code></sup><code>)) + 1</code>
</blockquote>
<p>The diagram below shows five examples of select operations on the same bit-string (b).</p>
<p>For the operation <code>select i</code>, the expression <code>2</code><sup><code>i-1</code></sup> computes a bit-string containing exactly one 1-bit at the i-th position in the bit-string (1-based).</p>
<p>The <code>pdep</code> operation is called to deposit this bit at the position corresponding to the n-th 1-bit in (b) to produce the result (c).</p>
<p>The number of trailing zeros (indicated by the <code>*</code>) when added to one yields the value of <code>select i</code>.</p>
<pre class="text"><code>           select 1          select 2          select 3         select 4         select 5        
(a) 1000000000000000  0100000000000000  0010000000000000 0010000000000000 0010000000000000
    ││││└───────┐     ││││└───────┐     ││││└───────┐    ││││└───────┐    ││││└───────┐   
    │││└────┐   │     │││└────┐   │     │││└────┐   │    │││└────┐   │    │││└────┐   │   
    ││└───┐ │   │     ││└───┐ │   │     ││└───┐ │   │    ││└───┐ │   │    ││└───┐ │   │   
    │└─┐  │ │   │     │└─┐  │ │   │     │└─┐  │ │   │    │└─┐  │ │   │    │└─┐  │ │   │   
(b) 1001001010001000  1001001010001000  1001001010001000 1001001010001000 1001001010001000
(c) 1000000000000000  0001000000000000  0000001000000000 0000000010000000 0000000000001000
(d) 1                 *** 4             ****** 7         ******** 9       ************ 13</code></pre>
<h2 id="splitting-a-bit-string-to-odd-and-even-bits">Splitting a bit-string to odd and even bits</h2>
<p>In last week’s <a href="../posts/2018-08-08-data-parallel-rank-select-bit-string-construction.html">post</a>, I explained that in order to create the rank-select bit-strings for an RFC compliant CSV format, I needed an operation that can take a bit-string and collect all the odd bits into one bit-string and all the even-bits into another.</p>
<p>The example I gave is reproduced here:</p>
<pre class="text"><code>text:     aaa,bbb,ccc␍␊&quot;a&quot;&quot;aa&quot;,&quot;b␍␊bb&quot;,&quot;c,cc&quot;
quotes:   00000000000001011001010000010100001
parens:   0000000000000(0)(00)0(00000)0(0000)
enters:   00000000000001001000010000000100000
exits:    00000000000000010001000000010000001</code></pre>
<p>In this post I will be using <code>odds</code> in place of <code>enters</code> because these are the <code>odd</code> bits and <code>evens</code> in place of <code>exits</code> because these are the <code>even</code> bits in our bit-string.</p>
<p>The opening parentheses <code>(</code> represents all the 1-bits that opening quotes of a quoted string and the closing parentheses <code>)</code> represents all the 1-bits that represents for the closing quotes.</p>
<p>We need to build <code>odds</code> which has all the odd 1-bits (ie. the opening quotes) and <code>leaves</code> which has all the even 1-bits (ie. the closing quotes).</p>
<p>We must somehow be able to produce the bit-strings <code>odds</code> and <code>evens</code> from the bit-string <code>quotes</code> very efficiently.</p>
<p>This is actually very easy with a single application of the <code>pdep</code> operation for each bit-string we produce:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="fu">~/</span>wrk<span class="fu">/</span>haskell<span class="fu">-</span>works<span class="fu">/</span>hw<span class="fu">-</span>rankselect<span class="fu">-</span>base <span class="fu">$</span></a>
<a class="sourceLine" id="cb13-2" data-line-number="2"></a>
<a class="sourceLine" id="cb13-3" data-line-number="3"><span class="fu">$</span> stack repl</a>
<a class="sourceLine" id="cb13-4" data-line-number="4">λ<span class="fu">&gt;</span> <span class="kw">import</span> <span class="dt">Data.Bits.Pdep</span></a>
<a class="sourceLine" id="cb13-5" data-line-number="5">λ<span class="fu">&gt;</span> <span class="kw">let</span> bs    <span class="fu">=</span> fromJust <span class="fu">$</span> bitRead <span class="st">&quot;00000000000001011001010000010100001000000000&quot;</span><span class="ot"> ::</span> <span class="dt">Word64</span></a>
<a class="sourceLine" id="cb13-6" data-line-number="6">λ<span class="fu">&gt;</span> <span class="kw">let</span> odds  <span class="fu">=</span> fromJust <span class="fu">$</span> bitRead <span class="st">&quot;10101010101010101010101010101010101010101010&quot;</span><span class="ot"> ::</span> <span class="dt">Word64</span></a>
<a class="sourceLine" id="cb13-7" data-line-number="7">λ<span class="fu">&gt;</span> <span class="kw">let</span> evens <span class="fu">=</span> fromJust <span class="fu">$</span> bitRead <span class="st">&quot;01010101010101010101010101010101010101010101&quot;</span><span class="ot"> ::</span> <span class="dt">Word64</span></a>
<a class="sourceLine" id="cb13-8" data-line-number="8">λ<span class="fu">&gt;</span> bitShow bs</a>
<a class="sourceLine" id="cb13-9" data-line-number="9"><span class="st">&quot;00000000 00000101 10010100 00010100 00100000 00000000 00000000 00000000&quot;</span></a>
<a class="sourceLine" id="cb13-10" data-line-number="10">λ<span class="fu">&gt;</span> bitShow <span class="fu">$</span> pdep odds bs</a>
<a class="sourceLine" id="cb13-11" data-line-number="11"><span class="st">&quot;00000000 00000100 10000100 00000100 00000000 00000000 00000000 00000000&quot;</span></a>
<a class="sourceLine" id="cb13-12" data-line-number="12">λ<span class="fu">&gt;</span> bitShow <span class="fu">$</span> pdep evens bs</a>
<a class="sourceLine" id="cb13-13" data-line-number="13"><span class="st">&quot;00000000 00000001 00010000 00010000 00100000 00000000 00000000 00000000&quot;</span></a></code></pre></div>
<p>I will leave it to the reader to work out why this works. 😉</p>
<h1 id="next-steps">Next steps</h1>
<p>We now have very fast rank-select operations for short bit-vectors of 64-bits, which is sufficient for CSV streaming because it allows us to process 64 bytes of CSV text at a time.</p>
<p>We also have the ability to split the odds and even bits out of our bit-string into separate bit-strings.</p>
<p>All the conceptual pieces needed to produce the necessary rank-select bit-strings for our high-performance RFC compliant CSV parser and pieces need to subsequently traverse the CSV text and extract interesting data have been described.</p>
<p>In my next post I will talk about how SIMD instructions can be used to make our parser go even faster!</p>
<p>Stay tuned!</p>]]></summary>
</entry>
<entry>
    <title>RFC compliant data-parallel CSV parsing</title>
    <link href="https://haskell-works.github.io/posts/2018-08-15-data-parallel-rfc-compliant-csv-parsing.html" />
    <id>https://haskell-works.github.io/posts/2018-08-15-data-parallel-rfc-compliant-csv-parsing.html</id>
    <published>2018-08-15T00:00:00Z</published>
    <updated>2018-08-15T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In last week’s <a href="../posts/2018-08-08-data-parallel-rank-select-bit-string-construction.html">post</a> I described how to exploit data-parallelism to build a rank-select bit-string for a <code>cut</code> compatible delimeter-separated-values format, parsing 8-bytes at-a-time.</p>
<p>In this post we will look at how to do the same for the CSV format described in <a href="https://tools.ietf.org/html/rfc4180">RFC4180</a>, where complicating factors such as quotes, escaping, and quoted control characters cannot be ignored.</p>
<h2 id="the-rfc-format">The RFC format</h2>
<p>The data-parallel parser will need to deal with the following cases where carriage-return characters are represented by <code>␍</code> and line-feed characters are represented by ␊:</p>
<p>When no quotations are used:</p>
<pre class="text"><code>aaa,bbb,ccc␍␊
zzz,yyy,xxx</code></pre>
<p>When quotations are used only around the entire fields containing no newline characters:</p>
<pre class="text"><code>&quot;aaa&quot;,&quot;bbb&quot;,&quot;ccc&quot;␍␊zzz,yyy,xxx</code></pre>
<p>When quotations are used only around the entire fields which may contain newline or delimiter characters:</p>
<pre class="text"><code>&quot;aaa&quot;,&quot;b␍␊
b,b&quot;,&quot;ccc&quot;␍␊
zzz,yyy,xxx</code></pre>
<p>When quotations are used within quoted fields represented by two consecutive double-quotes:</p>
<pre class="text"><code>&quot;aaa&quot;,&quot;b&quot;&quot;bb&quot;,&quot;ccc&quot;</code></pre>
<h2 id="the-parser-specification">The Parser Specification</h2>
<p>Because we are using rank-select bit-strings to index into the original text of the document and to minimise work, the parser is not expected to do additional processing to remove surrounding double quotes, escape quotes nor remove control characters.</p>
<p>These are instead left to a higher level parser built on top of our parser.</p>
<p>This means any strings the parser will yield will be a strict substring of the original document.</p>
<p>The parser will parse the earlier examples to produce results as described below.</p>
<p>When no quotations are used the substring representing the field text is returned in the result.</p>
<p>The line-feed byte will act as our newline character. Control chracters other than the row-delimiting line-feed byte are also included in the result with their closest field as is:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb5-1" data-line-number="1">[ [<span class="st">&quot;aaa&quot;</span>, <span class="st">&quot;bbb&quot;</span>, <span class="st">&quot;ccc␍&quot;</span>]</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">, [<span class="st">&quot;zzz&quot;</span>, <span class="st">&quot;yyy&quot;</span>, <span class="st">&quot;xxx&quot;</span>]</a>
<a class="sourceLine" id="cb5-3" data-line-number="3">]</a></code></pre></div>
<p>When quotations are used only around the entire fields containing no newline characters, the field is returned exactly as they appear in the original document including the surrounding double-quotes:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb6-1" data-line-number="1">[ [<span class="st">&quot;\&quot;aaa\&quot;&quot;</span>, <span class="st">&quot;\&quot;bbb\&quot;&quot;</span>,<span class="st">&quot;\&quot;ccc\&quot;␍&quot;</span>]</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">, [<span class="st">&quot;zzz&quot;</span>, <span class="st">&quot;yyy&quot;</span>, <span class="st">&quot;xxx&quot;</span>]</a>
<a class="sourceLine" id="cb6-3" data-line-number="3">]</a></code></pre></div>
<p>When quotations are used only around the entire fields containing line-feed characters or delimiters, such characters will be returned as part of their field in the result:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb7-1" data-line-number="1">[ [<span class="st">&quot;\&quot;aaa\&quot;&quot;</span>, <span class="st">&quot;\&quot;b␍␊b,b\&quot;&quot;</span>, <span class="st">&quot;\&quot;ccc\&quot;␍&quot;</span>]</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">, [<span class="st">&quot;zzz&quot;</span>, <span class="st">&quot;yyy&quot;</span>, <span class="st">&quot;xxx&quot;</span>]</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">]</a></code></pre></div>
<p>When quotations are used within quoted fields represented by two consecutive double-quotes, the consecutive double-quotes will be returned in the results as is:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb8-1" data-line-number="1">[ [<span class="st">&quot;\&quot;aaa\&quot;&quot;</span>, <span class="st">&quot;\&quot;b\&quot;\&quot;bb\&quot;&quot;</span>, <span class="st">&quot;\&quot;ccc\&quot;&quot;</span>]</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">]</a></code></pre></div>
<p>Returning substrings of the raw text as is in this way is good for performance because it means that in situtations where user-code only wishes to access some fields of each row in the document, they do not need to incur the costs of properly parsing the fields they don’t need.</p>
<p>This is also beneficial for cases where the user wishes to byte-copy fields from the input document into an output document, for example running a program to select desired fields from a CSV document into a new CSV document.</p>
<h2 id="deriving-the-strategy">Deriving the strategy</h2>
<p>In order to demonstrate the strategy, I will combine all the possible cases into a single document:</p>
<pre class="text"><code>aaa,bbb,ccc␍␊&quot;a&quot;&quot;aa&quot;,&quot;b␍␊bb&quot;,&quot;c,cc&quot;</code></pre>
<p>We will build the rank-select bit-strings for newlines and delimiters exactly as we did for the non-conformant parser in the last post:</p>
<pre class="text"><code>text:     aaa,bbb,ccc␍␊&quot;a&quot;&quot;aa&quot;,&quot;b␍␊bb&quot;,&quot;c,cc&quot;
markers:  00010001000010000000100010001001000
newlines: 00000000000010000000000010000000000</code></pre>
<p>Unfortunately, these rank-select bit-strings, are incorrect because they do not properly handle the case where line-feed or delimiter characters are embedded in a quoted field.</p>
<p>I’ve marked the incorrectly set bits with an asterisk <code>*</code>:</p>
<pre class="text"><code>text:     aaa,bbb,ccc␍␊&quot;a&quot;&quot;aa&quot;,&quot;b␍␊bb&quot;,&quot;c,cc&quot;
markers:  000100010000000000001000*000100*000
newlines: 000000000000000000000000*0000000000</code></pre>
<p>We will need to somehow clear the <code>*</code> bits in our rank-select bit-strings.</p>
<p>Since we desire to use a data-parallel approach to parsing CSV, we can start by building a rank-select bit-string for the double-quotes in our CSV document, just as we did for delimeters a new newlines.</p>
<pre class="text"><code>text:     aaa,bbb,ccc␍␊&quot;a&quot;&quot;aa&quot;,&quot;b␍␊bb&quot;,&quot;c,cc&quot;
markers:  000100010000000000001000*000100*000
newlines: 000000000000000000000000*0000000000
quotes:   00000000000001011001010000010100001</code></pre>
<p>But this doesn’t actually help me.</p>
<p>I want to clear all the bits marked by <code>*</code> without clearing the the other bits.</p>
<p>I can’t use <code>quotes</code> as a mask because everywhere there is a <code>1</code> bit regardless of whether it is correct (ie. <code>1</code>) or incorrect (ie. <code>*</code>), the corresponding bit in <code>quotes</code> is zero.</p>
<p>Furthermore I don’t actually care about the <code>1</code> bits in <code>quotes</code> because there can never be a delimiter or newline at a position that is already occupied by a quote <code>&quot;</code>.</p>
<p>Instead I need something like <code>mask</code> below, which has a <code>1</code> bit everywhere that is unquoted and a <code>0</code> bit everywhere that is quoted:</p>
<pre class="text"><code>text:     aaa,bbb,ccc␍␊&quot;a&quot;&quot;aa&quot;,&quot;b␍␊bb&quot;,&quot;c,cc&quot;
markers:  000100010000000000001000*000100*000
newlines: 000000000000000000000000*0000000000
quotes:   00000000000001011001010000010100001
mask:     1111111111111?0??00?1?00000?1?0000?</code></pre>
<p>I’ve also marked the locations that correspond to a double-quote as <code>?</code> because I don’t care about the bits at these locations because they can’t affect the outcome when I use <code>mask</code> to mask out the undersireable bits in the rank-select bit-string.</p>
<p>So how do I build a bit-string like <code>mask</code>?</p>
<p>The information I need to build this bit-string is contained withing the <code>quotes</code> bit-string. If I traverse the <code>quotes</code> bit-string bit-by-bit with the initial state of <code>1</code> and I flip my state every-time I encounter a <code>1</code> in <code>quotes</code>, I get the bit-string I need.</p>
<p>But this approach undermines the performance of the parser because now we are reduced to parsing the bit-string bit-by-bit, which is just as bad as parsing the CSV text byte-by-byte.</p>
<p>We have failed to exploit data parallelism to give us the performance we want.</p>
<p>But all is not lost.</p>
<p>Let’s look at our <code>quotes</code> bit-string more carefully. There are two kinds of <code>1</code> bits in our bit-string. All the <code>1</code> bits come in pairs.</p>
<p>In the scheme we just discussed earlier, the first of each pair marked by <code>(</code> takes our state from <code>1</code> to <code>0</code> to indicate we have entered the quoted state and the second of each pair marked by <code>)</code> takes out state from <code>0</code> to <code>1</code> to indicate we have exited the quoted state.</p>
<pre class="text"><code>quotes:   0000000000000(0)(00)0(00000)0(0000)</code></pre>
<p>Let’s say we somehow have a way to split the <code>quotes</code> bit-string into two separate bit-string very efficiently into an <code>enters</code> bit-string and and <code>exits</code> bit-string. Does that put us in a better position?</p>
<pre class="text"><code>quotes:   0000000000000(0)(00)0(00000)0(0000)
enters:   00000000000001001000010000000100000
exits:    00000000000000010001000000010000001
mask:     1111111111111?0??00?1?00000?1?0000?</code></pre>
<p>Sadly, the path forward still seems unclear.</p>
<p>What if we invert all the bits in <code>exits</code> to produce a new bit-string <code>~exits</code>?</p>
<pre class="text"><code>quotes:   0000000000000(0)(00)0(00000)0(0000)
enters:   00000000000001001000010000000100000
exits:    00000000000000010001000000010000001
~exits:   11111111111111101110111111101111110
mask:     1111111111111?0??00?1?00000?1?0000?</code></pre>
<p>Hmmm. It looks better because it seems closer to the desired bits in <code>mask</code>.</p>
<p>But the improvement is superficial. I’ve flipped some bits that needed to be a <code>1</code> to the desired value, but at a cost of flipping some other bits that need to be a <code>0</code> into a <code>1</code> as well.</p>
<p>I’ve flipped too much. Perhaps I am no closer after all.</p>
<p>But wait! I’ve not used <code>enters</code> yet!</p>
<p>I may have flipped too much, but enters tells me exactly from which point where I could compensate by flipping the following bits back to <code>0</code>.</p>
<p>What operation could possibly do that?</p>
<p>What I have are a bunch of consecutive ones separated by one or more <code>0</code>s. The bits I need to flip always form a zero more lengthed suffix of these consecutive <code>1</code>s. And the <code>enters</code> bit-string tells me the starting position of all those flips!</p>
<p>There is an operation that allows me to flip runs of <code>1</code> bits and it is the humble addition operator <code>+</code>.</p>
<p>If I add <code>enters</code> to <code>~exits</code>, the <code>1</code> bits in <code>enters</code> will cause a cascade of carries starting from their position through the runs of <code>1</code>s in <code>~exits</code> until the next <code>0</code>, where it will drop a <code>1</code> and the carries will terminate.</p>
<p>Let’s try that and see what we get:</p>
<pre class="text"><code>quotes:         0000000000000(0)(00)0(00000)0(0000)
enters:         00000000000001001000010000000100000
exits:          00000000000000010001000000010000001
~exits:         11111111111111101110111111101111110
enters+~exits:  11111111111110010001100000011000001
mask:           1111111111111?0??00?1?00000?1?0000?</code></pre>
<p>Like magic, the erroneously flipped bits corrected themselves, and all the bits that I care about match between <code>enters+~exits</code> and <code>mask</code>.</p>
<p>This means <code>enters+~exits</code> can serve as our mask.</p>
<p>So let’s perform this masking operation on our rank-select bit-strings:</p>
<pre class="text"><code>text:             aaa,bbb,ccc␍␊&quot;a&quot;&quot;aa&quot;,&quot;b␍␊bb&quot;,&quot;c,cc&quot;
markers:          000100010000100000001000*000100*000
newlines:         000000000000100000000000*0000000000
enters+~exits:    11111111111110010001100000011000001
masked-markers:   00010001000010000000100000001000000
masked-newlines:  00000000000010000000000000000000000</code></pre>
<p>Voilà!</p>
<p>We’ve successfully cleared the erroneously set bits at the positions marked by <code>*</code> and we have the correct rank-select bit-strings with which we can parse all our RFC4180 compliant CSV files without loss of data-parallelism!</p>
<h2 id="not-so-fast">Not so fast</h2>
<p>I mentioned briefly in order to pull this off I needed an operation that could split my <code>quotes</code> bit-string into separately into two bit-strings that marked the first and second bits of each pair of <code>1</code> bits in quotes:</p>
<pre class="text"><code>quotes:   0000000000000(0)(00)0(00000)0(0000)
enters:   00000000000001001000010000000100000
exits:    00000000000000010001000000010000001</code></pre>
<p>Without this, all things fall apart.</p>
<p>But do not fear. Next week, I will explain how to pull this off. Stay tuned!</p>]]></summary>
</entry>
<entry>
    <title>Data-Parallel Rank-Select Bit-String construction</title>
    <link href="https://haskell-works.github.io/posts/2018-08-08-data-parallel-rank-select-bit-string-construction.html" />
    <id>https://haskell-works.github.io/posts/2018-08-08-data-parallel-rank-select-bit-string-construction.html</id>
    <published>2018-08-08T00:00:00Z</published>
    <updated>2018-08-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>So far, I’ve <a href="../posts/2018-08-01-introduction-to-rank-select-bit-string.html">posted</a> about the problems with traditional parser and offered a glimpse of how they might be solved, but succinct data structures are quite alien and it isn’t obvious the pay-off will be worthwhile.</p>
<p>In this post, I demonstrate how use broadword programming techniques to exploit <a href="https://en.wikipedia.org/wiki/Data_parallelism">data-level parallelism</a> in the parsing of a CSV-like format.</p>
<p>Doing so allows us to parse the text 8-bytes at a time instead of one byte at a time as a traditional parser would.</p>
<p>For simplicity, I will be postponing the particular challenges of implementing the particulars of the <a href="https://tools.ietf.org/html/rfc4180">RFC standard for CSV</a> for a later time and instead work with a simplified format.</p>
<p>The simplified “CSV” grammar will only recognise delimiters and newlines and have no support for escaping.</p>
<p>The format I describe is effectively the kind of format that the <a href="https://en.wikipedia.org/wiki/Cut_(Unix)"><code>cut</code></a> command line tool can process, so <code>cut</code> will at some point serve as the performance baseline that I’m aiming to improve upon.</p>
<h2 id="data-parallelism">Data Parallelism</h2>
<p>Data parallelism describes a computation that can be decomposed into smaller computations that can be run in parallel.</p>
<p>We usually think of parsing is an inherently serial process due to the fact the parser must consume the input text one character at a time.</p>
<p>But because I’ve chosen a simplified format where the identification of delimiters and newlines are independent of what characters came before and what came after, there ought to be a way to parse the text more than one character at a time for the purposes of building a rank-select bit-string.</p>
<p>Our parser would need to generate a <code>1</code> bit for every newline in one of the rank-select bit-strings and a <code>1</code> bit for every newline and delimiter in the other.</p>
<p>Let’s use the example from the previous post to demonstrate how this can be done:</p>
<pre class="text"><code>&quot;name&quot;,&quot;age&quot;,&quot;profession&quot;␤John,30,Code Monkey␤Kyle,40,Data Scrubber
0000001000001000000000000100001001000000000001000010010000000000000
0000000000000000000000000100000000000000000001000000000000000000000</code></pre>
<p>The first line is the text we want to use to construct the following two bit-strings.</p>
<p>Note that <code>␤</code> represenes a newline ASCII character</p>
<h2 id="broadword-progamming">Broadword progamming</h2>
<p>Broadword programming, sometimes known as SWAR (SIMD Within A Register) uses large registers (in our case 64-bit integer registers) as small parallel computers that can process several pieces of information at a time.</p>
<p>We will be using this technique to parse our text 8-bytes at a time.</p>
<p>Before we start we will need the following operations:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="ot">(.&amp;.) ::</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span> <span class="co">-- Compute the bit-wise AND of two integers</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="ot">(.|.) ::</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span> <span class="co">-- Compute the bit-wise OR of two integers</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="ot">(.^.) ::</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span> <span class="co">-- Compute the bit-wise XOR of two integers</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="ot">comp  ::</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span>           <span class="co">-- Compute the bit-wise complement of an integer</span></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="ot">(.&gt;.) ::</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Count</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span>  <span class="co">-- Compute the right shift of an integer by the given offset in Big-Endian</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6">                                    <span class="co">-- Note, this is equivalent to a left shift of an integer in Little-Endian</span></a></code></pre></div>
<p>These operators are pretty standard, but pay close attention to the shift operator, which is the standard right shift operator.</p>
<p>When the bits are laid out in Little-Endian order the right shift operator will actually shift all the bits <em>to the LEFT</em>.</p>
<p>In all of the diagrams, bits and bytes will be laid out in Little-Endian because it is the natural layout for succinct data structures but it can be very confusing so bear with me and keep this in mind.</p>
<p>Our first task is to build the following rank-select bit-string from our text.</p>
<pre class="text"><code>&quot;name&quot;,&quot;age&quot;,&quot;profession&quot;␤John,30,Code Monkey␤Kyle,40,Data Scrubber
0000000000000000000000000100000000000000000001000000000000000000000</code></pre>
<p>To do this, we first create a 64-bit word that contains 8 x 8-bit packed integers each initialised to the ASCII code for the newline character. For example, the hexadecimal representation of the newline character is <code>0x0a</code>, so the 64-bit word we are contructing will be:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">let</span> wNewlines <span class="fu">=</span> <span class="bn">0x0101010101010101</span> <span class="fu">*</span> <span class="bn">0x0a</span><span class="ot"> ::</span> <span class="dt">Word64</span></a></code></pre></div>
<p>or</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">let</span> wNewlines <span class="fu">=</span> <span class="bn">0x0a0a0a0a0a0a0a0a</span><span class="dt">L</span><span class="ot"> ::</span> <span class="dt">Word64</span></a></code></pre></div>
<p>The next step is to take the text and pad it with zero bytes to the nearest 64-bit boundary. Then take the entire text and cast it to a vector of Little-Endian 64-bit integers.</p>
<p>This leads to a view of memory shown below indicated by <code>text</code>.</p>
<pre class="text"><code>             Bytes packed into Little-Endian Word64 integers
           ┌─────────────────────────┼─────────────────────────┐
┌──────────┴──────────┐   ┌──────────┴──────────┐   ┌──────────┴──────────┐
&quot;  n  a  m  e  &quot;  ,  &quot;    a  g  e  &quot;  ,  &quot;  p  r    o  f  e  s  s  i  o  n   
22 6e 61 6d 65 22 2c 22   61 67 65 22 2c 22 70 72   6f 66 65 73 73 69 6f 6e   text ─────────┐
0a 0a 0a 0a 0a 0a 0a 0a   0a 0a 0a 0a 0a 0a 0a 0a   0a 0a 0a 0a 0a 0a 0a 0a   mask ────────┐│
28 64 6b 67 6f 28 26 28   6b 6d 6f 28 26 28 7a 78   65 6c 6f 79 79 63 65 64   comparison &lt;┬┴┘ (.^.)
0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0    newlines &lt;──┘ cmpzero
                                                                            
                                                                            
  ┌──┐                                                            ┌──┐                        
&quot; │$ │J  o  h  n  ,  3    0  ,  C  o  d  e     M    o  n  k  e  y │␤ │K  y 
22│0a│4a 6f 68 6e 2c 33   30 2c 43 6f 64 65 20 4d   6f 6e 6b 65 79│0a│4b 79   text ─────────┐
0a│0a│0a 0a 0a 0a 0a 0a   0a 0a 0a 0a 0a 0a 0a 0a   0a 0a 0a 0a 0a│0a│0a 0a   mask ────────┐│
28│00│40 65 62 64 26 39   3a 26 49 65 6e 6f 2a 47   65 64 61 6f 73│00│41 73   comparison &lt;┬┴┘ (.^.)
0 │1 │0  0  0  0  0  0    0  0  0  0  0  0  0  0    0  0  0  0  0 │1 │0  0    newlines &lt;──┘ cmpzero
  └┬─┘                                                            └┬─┘  
   └──────────────────────────────────────────────┬────────────────┘
                                                  │                            
                                                  │         ┌──┐               
l  e  ,  4  0  ,  D  a    t  a     S  c  r  u  b  │ b  e  r │␤ ├───────────┐   
6c 65 2c 34 30 2c 44 61   74 61 20 53 63 72 75 62 │ 62 65 72│0a│00 00 00 00│  text ─────────┐
0a 0a 0a 0a 0a 0a 0a 0a   0a 0a 0a 0a 0a 0a 0a 0a │ 0a 0a 0a│0a│0a 0a 0a 0a│  mask ────────┐│
66 6f 26 3e 3a 26 4e 6b   7e 6b 2a 59 69 78 7f 68 │ 68 6f 78│00│0a 0a 0a 0a│  comparison &lt;┬┴┘ (.^.)
0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  │ 0  0  0 │1 │0  0  0  0 │  newlines &lt;──┘ cmpzero
                                                  │         └┬─┴───┬───────┘  
            Bits corresponding to newlines that   │          │     └─Padding
            need to be set to 1 ──────────────────┴──────────┘</code></pre>
<p>Then for each 64-bit value in the vector take the exclusive or <code>(.^.)</code> with the <code>wNewlines</code> mask. The resulting vector of 64-bit vector when cast back to a vector of bytes will then contain a zero value for every character in the original text that was a newline and a non-zero value otherwise.</p>
<p>This is very close to what we want. All we need to do now is to collapse every non-zero byte into a <code>0</code> bit and every zero byte to a <code>1</code> bit.</p>
<p>The problem we are trying to solve can be exemplified by the following example where we need a function <code>cmpzero</code> that condenses the bytes in the <code>comparison</code> row to the bits in the <code>newlines</code> row:</p>
<pre class="text"><code>              ┌──┐
65 64 61 6f 73│00│41 73   comparison ─┐
0  0  0  0  0 │1 │0  0    newlines &lt;──┘
              └──┘</code></pre>
<p>This can be done in a series of bit-wise manipulations described below:</p>
<pre class="text"><code>T   text ┌─── 10100110 00100110 10000110 11110110 11001110 00000000 10000010 11001110
         │                                                                           
    mask │┌── 00001111 00001111 00001111 00001111 00001111 00001111 00001111 00001111
A   (.&amp;.)├┴─&gt; 00000110 00000110 00000110 00000110 00001110 00000000 00000010 00001110 ─┐    
B        │  ┌ 01100000 01100000 01100000 01100000 11100000 00000000 00100000 11100000 &lt;┘ (.&gt;. 4)
         │  └────────────────────────────────────────────────────────────────────────────┐
    mask │┌── 11110000 11110000 11110000 11110000 11110000 11110000 11110000 11110000    │
C   (.&amp;.)└┴─&gt; 10100000 00100000 10000000 11110000 11000000 00000000 10000000 11000000 ──┐│
                                                                                        ││
D        ┌─── 11100000 01100000 11100000 11110000 11100000 00000000 10100000 11100000 &lt;─┴┘(.|.)
         │                                                                             
    mask │┌── 00110000 00110000 00110000 00110000 00110000 00110000 00110000 00110000 mask 
E   (.&amp;.)├┴─&gt; 00100000 00100000 00100000 00110000 00100000 00000000 00100000 00100000 ─┐    
F        │  ┌ 10000000 10000000 10000000 11000000 10000000 00000000 10000000 10000000 &lt;┘ (.&gt;. 2)
         │  └────────────────────────────────────────────────────────────────────────────┐
G   mask │┌── 11000000 11000000 11000000 11000000 11000000 11000000 11000000 11000000    │
H   (.&amp;.)└┴─&gt; 11000000 01000000 11000000 11000000 11000000 00000000 10000000 11000000 ──┐│
                                                                                        ││
I        ┌─── 11000000 11000000 11000000 11000000 11000000 00000000 10000000 11000000 &lt;─┴┘(.|.)
         │                                                                            
    mask │┌── 01000000 01000000 01000000 01000000 01000000 00000000 01000000 01000000 
J   (.&amp;.)├┴─&gt; 01000000 01000000 01000000 01000000 01000000 00000000 01000000 01000000 ─┐    
K        │  ┌ 10000000 10000000 10000000 10000000 10000000 00000000 10000000 10000000 &lt;┘ (.&gt;. 1)
         │  └────────────────────────────────────────────────────────────────────────────┐
    mask │┌── 10000000 10000000 10000000 10000000 10000000 00000000 10000000 10000000    │
L   (.&amp;.)└┴─&gt; 10000000 10000000 10000000 10000000 10000000 00000000 10000000 10000000 ──┐│
                                                                                        ││
M             10000000 10000000 10000000 10000000 10000000 00000000 10000000 10000000 &lt;─┴┘(.|.)
              │        │        │        └───┐┌───┘        │        │        │
              │        │        └───────────┐││┌───────────┘        │        │
              │        └───────────────────┐││││┌───────────────────┘        │
              └───────────────────────────┐││││││┌───────────────────────────┘
                                          11111011─┐pext
                                          00000100&lt;┘comp</code></pre>
<p>We start with the following computations:</p>
<ul>
<li>At <code>T</code> we have our 64-bit integer that contains 8-bytes of our text</li>
<li>At <code>A</code> we mask out first half of every byte in our word <code>T</code>.</li>
<li>At <code>B</code> we shift the second half of every byte into the first half position of every byte in our word.</li>
<li>At <code>C</code> we mask out the second half of every byte in our word <code>T</code>.</li>
<li>At <code>D</code> we compute <code>A .|. C</code></li>
</ul>
<p>At this point we have compressed result into the first half of every byte. We repeat this to compress further to the first quarter of our bytes similarly:</p>
<ul>
<li>At <code>E</code> we mask out first quarter of every byte in our word <code>D</code>.</li>
<li>At <code>F</code> we shift the second quarter of every byte into the first quarter of every byte in our word.</li>
<li>At <code>H</code> we mask out the second quarter of every byte in our word <code>D</code>.</li>
<li>At <code>I</code> we compute <code>F .|. H</code></li>
</ul>
<p>Finally we do this one more time to compress the first quarter of every byte in our word to the first bit of every byte in our word.</p>
<ul>
<li>At <code>J</code> we mask out first bit of every byte in our word <code>H</code>.</li>
<li>At <code>K</code> we shift the second bit of every byte into the first bit of every byte in our word.</li>
<li>At <code>L</code> we mask out the second bit of every byte in our word <code>H</code>.</li>
<li>At <code>M</code> we compute <code>J .|. L</code></li>
</ul>
<p>Now we are two steps away from the 8-bits of rank-select bit-string we need for our 8 input characters.</p>
<p>We need some way to extract the first bit of every byte in our word, an operation I will call <code>pext</code> or parallel extract, and then take the complement of the result to get the rank-select bit-string we sought.</p>
<p>The other rank-select bit-string which marks delimiters and newlines can be derived by applying the same algorithm for the delimiters and the newlines separately then taking the bitwise OR <code>(.|.)</code> of the two resulting bit-strings.</p>
<p>The resulting code is show below.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="ot">testWord8s ::</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">testWord8s w <span class="fu">=</span>  <span class="kw">let</span> w8s <span class="fu">=</span> w</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">                    w4s <span class="fu">=</span> (w8s <span class="fu">.&amp;.</span> <span class="bn">0x0f0f0f0f0f0f0f0f</span>) <span class="fu">.|.</span> ((w8s <span class="fu">.&amp;.</span> <span class="bn">0xf0f0f0f0f0f0f0f0</span>) <span class="fu">.&gt;.</span> <span class="dv">4</span>)</a>
<a class="sourceLine" id="cb9-4" data-line-number="4">                    w2s <span class="fu">=</span> (w4s <span class="fu">.&amp;.</span> <span class="bn">0x0707070707070707</span>) <span class="fu">.|.</span> ((w4s <span class="fu">.&amp;.</span> <span class="bn">0x7070707070707070</span>) <span class="fu">.&gt;.</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb9-5" data-line-number="5">                    w1s <span class="fu">=</span> (w2s <span class="fu">.&amp;.</span> <span class="bn">0x0303030303030303</span>) <span class="fu">.|.</span> ((w2s <span class="fu">.&amp;.</span> <span class="bn">0x3030303030303030</span>) <span class="fu">.&gt;.</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb9-6" data-line-number="6">                <span class="kw">in</span>  pext w1s <span class="bn">0x0101010101010101</span></a>
<a class="sourceLine" id="cb9-7" data-line-number="7"><span class="ot">{-# INLINE testWord8s #-}</span></a></code></pre></div>
<p>All up we’ve used the following operations:</p>
<ul>
<li><code>(.&amp;.)</code> x 6</li>
<li><code>(.|.)</code> x 3</li>
<li><code>(.&gt;.)</code> x 3</li>
<li><code>pext</code> x 1</li>
<li><code>load</code> x 1</li>
<li><code>store</code> x 1</li>
</ul>
<p>Which adds up to <code>13</code> very fast register only instructions plus <code>2</code> implied memory instructions.</p>
<h1 id="optimising-our-bit-string-construction-code">Optimising our bit-string construction code</h1>
<p>If you look at the <code>M</code> row in the diagram you will notice that near the end of the computation we only use the least significant bit from each of the 8 bytes in our word and don’t actually care what the values of the other bits are.</p>
<p>We can exploit this fact to remove some of the operations from our computation by marking those bits as don’t care or <code>x</code>, and tracing those bits backwards through the computation and then figuring out which operations we can omit.</p>
<pre class="text"><code>T   text ┌─── 10100110 00100110 10000110 11110110 11001110 00000000 10000010 11001110
         │                                                                           
A   noop ├──&gt; xxxx0110 xxxx0110 xxxx0110 xxxx0110 xxxx1110 xxxx0000 xxxx0010 xxxx1110 ─┐    
B        │  ┌ 0110xxxx 0110xxxx 0110xxxx 0110xxxx 1110xxxx 0000xxxx 0010xxxx 1110xxxx &lt;┘ (.&gt;. 4)
         │  └────────────────────────────────────────────────────────────────────────────┐
C   noop └──&gt; 1010xxxx 0010xxxx 1000xxxx 1111xxxx 1100xxxx 0000xxxx 1000xxxx 1100xxxx ──┐│
                                                                                        ││
D        ┌─── 1110xxxx 0110xxxx 1110xxxx 1111xxxx 1110xxxx 0000xxxx 1010xxxx 1110xxxx &lt;─┴┘(.|.)
         │                                                                             
E   noop ├──&gt; xx10xxxx xx10xxxx xx10xxxx xx11xxxx xx10xxxx xx00xxxx xx10xxxx xx10xxxx ─┐    
F        │  ┌ 10xxxxxx 10xxxxxx 10xxxxxx 11xxxxxx 10xxxxxx 00xxxxxx 10xxxxxx 10xxxxxx &lt;┘ (.&gt;. 2)
         │  └────────────────────────────────────────────────────────────────────────────┐
G   noop └──&gt; 11xxxxxx 01xxxxxx 11xxxxxx 11xxxxxx 11xxxxxx 00xxxxxx 10xxxxxx 11xxxxxx ──┐│
                                                                                        ││
I        ┌─── 11xxxxxx 11xxxxxx 11xxxxxx 11xxxxxx 11xxxxxx 00xxxxxx 10xxxxxx 11xxxxxx &lt;─┴┘(.|.)
         │                                                                            
J   noop ├──&gt; x1xxxxxx x1xxxxxx x1xxxxxx x1xxxxxx x1xxxxxx x0xxxxxx x1xxxxxx 01xxxxxx ─┐    
K        │  ┌ 1xxxxxxx 1xxxxxxx 1xxxxxxx 1xxxxxxx 1xxxxxxx x0xxxxxx 1xxxxxxx 1xxxxxxx &lt;┘ (.&gt;. 1)
         │  └────────────────────────────────────────────────────────────────────────────┐
L   noop └──&gt; 1xxxxxxx 1xxxxxxx 1xxxxxxx 1xxxxxxx 1xxxxxxx 0xxxxxxx 1xxxxxxx 1xxxxxxx ──┐│
                                                                                        ││
M             1xxxxxxx 1xxxxxxx 1xxxxxxx 1xxxxxxx 1xxxxxxx 0xxxxxxx 1xxxxxxx 1xxxxxxx &lt;─┴┘(.|.)
              │        │        │        └───┐┌───┘        │        │        │
              │        │        └───────────┐││┌───────────┘        │        │
              │        └───────────────────┐││││┌───────────────────┘        │
              └───────────────────────────┐││││││┌───────────────────────────┘
                                          11111011─┐pext
                                          00000100&lt;┘comp</code></pre>
<p>As a result of tracing the don’t care or <code>x</code> bits backwards through the computation, I was able to remove six masks and six AND <code>(.&amp;.)</code> operations.</p>
<p>I left the rows <code>A</code>, <code>C</code>, <code>E</code>, <code>G</code>, <code>J</code>, and <code>L</code> in as non-operations (<code>noop</code>) because I wanted to annotate the additional bits I don’t care beyond those I already don’t care about in the original value.</p>
<p>The resulting code is much simpler and faster:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="ot">testWord8s ::</span> <span class="dt">Word64</span> <span class="ot">-&gt;</span> <span class="dt">Word64</span></a>
<a class="sourceLine" id="cb11-2" data-line-number="2">testWord8s w <span class="fu">=</span>  <span class="kw">let</span> w8s <span class="fu">=</span> w</a>
<a class="sourceLine" id="cb11-3" data-line-number="3">                    w4s <span class="fu">=</span> w8s <span class="fu">.|.</span> (w8s <span class="fu">.&gt;.</span> <span class="dv">4</span>)</a>
<a class="sourceLine" id="cb11-4" data-line-number="4">                    w2s <span class="fu">=</span> w4s <span class="fu">.|.</span> (w4s <span class="fu">.&gt;.</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb11-5" data-line-number="5">                    w1s <span class="fu">=</span> w2s <span class="fu">.|.</span> (w2s <span class="fu">.&gt;.</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb11-6" data-line-number="6">                <span class="kw">in</span>  pext w1s <span class="bn">0x0101010101010101</span></a>
<a class="sourceLine" id="cb11-7" data-line-number="7"><span class="ot">{-# INLINE testWord8s #-}</span></a></code></pre></div>
<p>The optimisations meas we now use only these operations:</p>
<ul>
<li><code>(.|.)</code> x 3</li>
<li><code>(.&gt;.)</code> x 3</li>
<li><code>pext</code> x 1</li>
<li><code>load</code> x 1</li>
<li><code>store</code> x 1</li>
</ul>
<p>This adds up to <code>7</code> very fast register only instructions plus <code>2</code> implied memory instructions, which is very close to <code>1</code> instruction per byte for each rank-select bit-string constructed.</p>
<h2 id="unanswered-questions">Unanswered questions</h2>
<p>What’s nice about it is that we are parsing 8-bytes at a time using fewer instructions and we’ve managed to avoid any branches or memory allocations within each iteration that could slow the iteration down.</p>
<p>Nevertheless, some benchmarks will be necessary to compare this approach to one that parses a byte at a time.</p>
<p>You may have noticed that I have used the <code>pext</code> operation without properly describing how it works nor explained why that operation should be fast.</p>
<p>I will follow up in a future post to explain the <code>pext</code> operation in detail and offer some benchmarks to show the degree of speed up we might expect from exploiting data parallelism in our parsers.</p>
<h2 id="source-code">Source code</h2>
<p>You can play with the source code <a href="https://github.com/haskell-works/hw-simd/blob/master/src/HaskellWorks/Data/Simd/Internal/Bits.hs#L9">here</a>.</p>]]></summary>
</entry>
<entry>
    <title>Introduction to the rank-select bit-string</title>
    <link href="https://haskell-works.github.io/posts/2018-08-01-introduction-to-rank-select-bit-string.html" />
    <id>https://haskell-works.github.io/posts/2018-08-01-introduction-to-rank-select-bit-string.html</id>
    <published>2018-08-01T00:00:00Z</published>
    <updated>2018-08-01T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p><a href="../posts/2018-07-25-problem-of-parsing-large-datasets.html">Last week</a> we looked at how traditional whole-document parsers struggle to parse big files.</p>
<p><img style="float: right; height: 300px; width: 300px;" src="/images/golden-toilet.png"> Such parsers both too use much memory and are too slow, being orders of magnitude slower than what IO bandwidth would allow.</p>
<p>In some sense, we can understand the slowness as a consequence large memory usage: All that memory access does not come for free.</p>
<p>Traditional whole-document parsers spend a lot of time allocating memory, assigning pointers, following indirections and touching new memory that isn’t cached in the CPU cache where it could have been accessed much more quickly.</p>
<p>To achieve high performance, the parser needs to do as little possible, but traditional parsers are actually creating a lot of work for the hardware, that is incidental to solving the problem of making the document data accessible and much of that overhead is hidden from us, the developer, by language and hardware abstractions, so the overhead is easy to overlook.</p>
<p>We have seen how objects are severely expensive, especially when allocated en-mass. For our use-case their cost disproportionately exceeds their utility.</p>
<h1 id="if-not-objects-then-what">If not objects then what</h1>
<p>If we want to minimise memory usage, the first thing you should do is avoid duplicating data.</p>
<p>All the data we want to access is already in the document. Copying that data into intermediate objects so that we can work with them is wasteful.</p>
<p><img style="float: right; height: 300px; width: 300px;" src="/images/bits-in-perspective.jpg"> Instead we want to reuse the data in its original form as much as possible and leave the parsing of small individual elements of the document to the last moment just before we use them and in that way avoid parsing all the parts of the document we don’t need.</p>
<p>What prevents us from doing that exactly that is that we lack the means to navigate the structure of the document to locate the various pieces of data in the document we are interested in.</p>
<p>This structure is exactly what our object-based document object model provided, but to avoid paying their dues, we must find another way.</p>
<p>But if not objects, then what?</p>
<p>If you want to find something extremely small and light weight, you could do worse than choose the humble bit. It is 64 times smaller than a pointer and many multiples of that smaller than an object.</p>
<p>So let’s do exactly that: Let’s use bits!</p>
<h1 id="the-rank-select-bit-string">The rank-select bit-string</h1>
<p>Before we can pull this off we are going to have to learn us some concepts.</p>
<p>Imagine a string of bits. Not unlike the following:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">let</span> bs <span class="fu">=</span> <span class="st">&quot;101000000010000000100000010001000000100000&quot;</span></a></code></pre></div>
<p>In order to query this bit-string we will be using two very powerful query operations <strong>rank</strong> and <strong>select</strong>.</p>
<p>The pseudocode for these to operations are provided below in Haskell which you can drop into your Haskell repl to observe their behaviours:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">import</span> <span class="dt">Data.List</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="ot">popCount1 ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">Int</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4">popCount1 bs <span class="fu">=</span> length (filter (<span class="fu">==</span> <span class="ch">&#39;1&#39;</span>) bs)</a>
<a class="sourceLine" id="cb2-5" data-line-number="5"></a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="ot">rank1 ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7">rank1 bs n <span class="fu">=</span> popCount1 (take n bs)</a>
<a class="sourceLine" id="cb2-8" data-line-number="8"></a>
<a class="sourceLine" id="cb2-9" data-line-number="9"><span class="ot">select1 ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span></a>
<a class="sourceLine" id="cb2-10" data-line-number="10">select1 bs n <span class="fu">=</span> length (head (dropWhile ((<span class="fu">&lt;</span> n) <span class="fu">.</span> popCount1) (inits (filter isBinary bs))))</a>
<a class="sourceLine" id="cb2-11" data-line-number="11">  <span class="kw">where</span> isBinary c <span class="fu">=</span> c <span class="fu">==</span> <span class="ch">&#39;0&#39;</span> <span class="fu">||</span> c <span class="fu">==</span> <span class="ch">&#39;1&#39;</span></a></code></pre></div>
<p>The first function <code>popCount1</code> is the <strong>population</strong> operation (sometimes called the <a href="https://en.wikipedia.org/wiki/Hamming_weight">hamming weight</a>). It tells us how many <code>1</code> bits there are in our bit-string.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb3-1" data-line-number="1">λ<span class="fu">&gt;</span> popCount1 bs</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="dv">7</span></a></code></pre></div>
<p>The second function <code>rank1</code> is the <strong>rank</strong> operation which tells us the population count of the length <code>n</code> prefix of our bit-string.</p>
<p>Here are some example <strong>rank</strong> queries:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb4-1" data-line-number="1">λ<span class="fu">&gt;</span> rank1 bs <span class="dv">0</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="dv">0</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3">λ<span class="fu">&gt;</span> rank1 bs <span class="dv">1</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="dv">1</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5">λ<span class="fu">&gt;</span> rank1 bs <span class="dv">2</span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6"><span class="dv">1</span></a>
<a class="sourceLine" id="cb4-7" data-line-number="7">λ<span class="fu">&gt;</span> rank1 bs <span class="dv">3</span></a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="dv">2</span></a>
<a class="sourceLine" id="cb4-9" data-line-number="9">λ<span class="fu">&gt;</span> rank1 bs <span class="dv">14</span></a>
<a class="sourceLine" id="cb4-10" data-line-number="10"><span class="dv">3</span></a></code></pre></div>
<p>The third function <code>select1</code> is the <strong>select</strong> operation which tells us smallest prefix of the given bit-string with the given population <code>n</code>.</p>
<p>Here are some example <strong>select</strong> queries:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb5-1" data-line-number="1">λ<span class="fu">&gt;</span> select1 bs <span class="dv">0</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="dv">0</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3">λ<span class="fu">&gt;</span> select1 bs <span class="dv">1</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="dv">1</span></a>
<a class="sourceLine" id="cb5-5" data-line-number="5">λ<span class="fu">&gt;</span> select1 bs <span class="dv">2</span></a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="dv">3</span></a>
<a class="sourceLine" id="cb5-7" data-line-number="7">λ<span class="fu">&gt;</span> select1 bs <span class="dv">3</span></a>
<a class="sourceLine" id="cb5-8" data-line-number="8"><span class="dv">11</span></a>
<a class="sourceLine" id="cb5-9" data-line-number="9">λ<span class="fu">&gt;</span> select1 bs <span class="dv">4</span></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="dv">19</span></a></code></pre></div>
<p>In less precise terms, the <strong>rank</strong> gives us how many <code>1s</code> up to a given position <code>n</code> in our bit-string and <strong>select</strong> gives us the position of the <code>n</code><sup><code>th</code></sup> <code>1</code> in our bit-string.</p>
<h1 id="rank-select-bit-string-as-an-index-into-json">Rank-Select Bit-String as an index into JSON</h1>
<p>We will now use the rank-select bit-string to index into JSON, which is to say we will use it to locate interesting locations in our JSON document that correspond to the beginning of JSON nodes.</p>
<p>In our semi-index, every bit in the rank-select bit-string corresponds to a byte in the original document of the same position. The value of each bit is chosen such that when the byte represents the start of a node in the document it will be set to <code>1</code>. Otherwise it will be set to <code>0</code>.</p>
<p>For JSON, the beginning of every object (indicated by <code>{</code>), every array (indiciated by <code>[</code>), every field or value will be marked with a <code>1</code>, and all other bytes are marked with a <code>0</code>.</p>
<p>The example below demonstrates this mapping from bytes to bits:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode json"><code class="sourceCode json"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="fu">{</span> <span class="dt">&quot;name&quot;</span><span class="fu">:</span> <span class="st">&quot;John&quot;</span><span class="fu">,</span> <span class="dt">&quot;age&quot;</span><span class="fu">:</span> <span class="dv">30</span><span class="fu">,</span> <span class="dt">&quot;car&quot;</span><span class="fu">:</span> <span class="kw">null</span><span class="fu">,</span> <span class="er">colors</span><span class="fu">:</span> <span class="ot">[</span><span class="dv">1</span><span class="ot">,</span> <span class="dv">2</span><span class="ot">,</span> <span class="dv">3</span><span class="ot">]</span> <span class="fu">}</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="er">1010000000100000001000000100010000001000001000000011001001000</span></a></code></pre></div>
<p>What this gives us is the ability to locate the <code>n</code><sup><code>th</code></sup> node in the document with <strong>rank-select</strong> operations.</p>
<p>For example the <code>6</code><sup><code>th</code></sup> node is marked by the <code>6</code><sup><code>th</code></sup> <code>1</code> bit at the location that corresponds to the field-name <code>&quot;car&quot;</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb7-1" data-line-number="1">λ<span class="fu">&gt;</span> <span class="kw">let</span> text <span class="fu">=</span> <span class="st">&quot;{ \&quot;name\&quot;: \&quot;John\&quot;, \&quot;age\&quot;: 30, \&quot;car\&quot;: null, numbers: [1, 2, 3] }&quot;</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2">λ<span class="fu">&gt;</span> <span class="kw">let</span> bs   <span class="fu">=</span> <span class="st">&quot;101 00000 001 00000 0010 00000 10001000 00010 000010000000011001001000&quot;</span></a>
<a class="sourceLine" id="cb7-3" data-line-number="3">λ<span class="fu">&gt;</span> <span class="kw">let</span> offset <span class="fu">=</span> select1 bs <span class="dv">6</span></a>
<a class="sourceLine" id="cb7-4" data-line-number="4"><span class="dv">31</span></a>
<a class="sourceLine" id="cb7-5" data-line-number="5">λ<span class="fu">&gt;</span> drop (offset <span class="fu">-</span> <span class="dv">1</span>) text</a>
<a class="sourceLine" id="cb7-6" data-line-number="6"><span class="st">&quot;\&quot;car\&quot;: null, numbers: [1, 2, 3] }&quot;</span></a></code></pre></div>
<p>In another example, the <code>9</code><sup><code>th</code></sup> node is marked by the <code>9</code><sup><code>th</code></sup> <code>1</code> bit at the location that corresponds to the beginning of the JSON array:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb8-1" data-line-number="1">λ<span class="fu">&gt;</span> <span class="kw">let</span> text <span class="fu">=</span> <span class="st">&quot;{ \&quot;name\&quot;: \&quot;John\&quot;, \&quot;age\&quot;: 30, \&quot;car\&quot;: null, numbers: [1, 2, 3] }&quot;</span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2">λ<span class="fu">&gt;</span> <span class="kw">let</span> bs   <span class="fu">=</span> <span class="st">&quot;101 00000 001 00000 0010 00000 10001000 00010 000010000000011001001000&quot;</span></a>
<a class="sourceLine" id="cb8-3" data-line-number="3">λ<span class="fu">&gt;</span> <span class="kw">let</span> offset <span class="fu">=</span> select1 bs <span class="dv">9</span></a>
<a class="sourceLine" id="cb8-4" data-line-number="4"><span class="dv">52</span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5">λ<span class="fu">&gt;</span> drop (offset <span class="fu">-</span> <span class="dv">1</span>) text</a>
<a class="sourceLine" id="cb8-6" data-line-number="6"><span class="st">&quot;[1, 2, 3] }&quot;</span></a></code></pre></div>
<p>You may notice that each successive <code>1</code> bit in the rank-select bit-string identifies nodes of the document according to pre-order traversal.</p>
<p>It is also worth noting that the rank-select bit-string in combination with the original text can be used to identify the type of the node in <code>O(1)</code> time, by testing the character pointed to by the rank-select bit-string.</p>
<p>For example, we know the <code>6</code><sup><code>th</code></sup> node in the document is a string because the character at line <code>31</code> is a <code>&quot;</code>, whilst the <code>9</code><sup><code>th</code></sup> node is an array because the character at line <code>52</code> is a <code>[</code>.</p>
<h1 id="rank-select-bit-string-as-an-index-into-csv">Rank-Select Bit-String as an index into CSV</h1>
<p>Rank-select bit-strings can be used to index into a CSV document in a similar fashion, but I have chosen to use two rank-select bit-strings instead of one.</p>
<p>Take the following CSV document</p>
<pre class="text"><code>&quot;name&quot;,&quot;age&quot;,&quot;profession&quot;
John,30,Code Monkey
Kyle,40,Data Scrubber</code></pre>
<p>I will represent this document on a single line for easier comparison with the two rank-select bit-strings that follow:</p>
<pre class="text"><code>&quot;name&quot;,&quot;age&quot;,&quot;profession&quot;␤John,30,Code Monkey␤Kyle,40,Data Scrubber
0000001000001000000000000100001001000000000001000010010000000000000
0000000000000000000000000100000000000000000001000000000000000000000</code></pre>
<p>The first rank-select bit-string marks both delimiters and newlines and helps us find the beginning of fields, whilst the other rank-select bit-string marks newlines only and helps us find the beginning of rows.</p>
<p>Having two rank-select bit-strings affords us operations like row count, and field count (either per document or per row) without having to inspect the original document text at all.</p>
<p>If you’re interested with playing with the haskell-works library which works on real bit-vectors (rather than emulation on strings), head over to the <a href="http://github.com/haskell-works/hw-rankselect-base">hw-rankselect-base</a> project page.</p>
<h1 id="other-ingredients-to-a-fast-json-or-csv-parser">Other ingredients to a fast JSON or CSV parser</h1>
<p>A rank-select bit-string by itself won’t get us a fast JSON or CSV parser.</p>
<p>We will need high performance <strong>rank</strong> and <strong>select</strong> operations for both short and very long bit-strings to make this practical.</p>
<p>We haven’t talked about the implications this has for whole document or streaming parsers either.</p>
<p>Nor have we discussed how to build rank-select bit-strings efficiently and then use them to parse the document in a way that is competitive with traditional parsers.</p>
<p>Furthermore, the rank-select bit-string is insufficient for parsing heirarchical document formats such as JSON because it does not allow for tree traversal.</p>
<p>Whilst we know the nodes are ordered in pre-order traversal order, we have lost information about parent-child or sibling-sibling relationships between nodes, and so are unable traverse in such a way as to, for example, construct a tree of nodes that resemble the document.</p>
<p>An additional index is required to make proper tree-traversal of the document possible.</p>
<p>Alas, these and other questions must remain for a future post.</p>
<h1 id="references">References</h1>
<p><a href="http://www.di.unipi.it/~ottavian/files/semi_index_cikm.pdf">Semi-Indexing Semi-Structured Data in Tiny Space</a></p>]]></summary>
</entry>
<entry>
    <title>The problem of parsing large datasets</title>
    <link href="https://haskell-works.github.io/posts/2018-07-25-problem-of-parsing-large-datasets.html" />
    <id>https://haskell-works.github.io/posts/2018-07-25-problem-of-parsing-large-datasets.html</id>
    <published>2018-07-25T00:00:00Z</published>
    <updated>2018-07-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In data processing, the volume of data can be so large that the amount of time it takes to process a file matters. In my work, I try to optimise such jobs so that it is more efficient, but surprisingly, it is often not the business logic that is the bottleneck, but the parsing of files itself that consumes large amounts of CPU and memory.</p>
<h1 id="memory-usage">Memory usage</h1>
<p>Memory in particular can be a serious problem because we store files in S3 where the pricing model and latency of <code>GET</code> queries favours the storage of large files in the hundreds of MBs each.</p>
<p>The danger with storing such large files, however, is we can run out of memory just trying to parse them.</p>
<p>To illustrate the problem, here is a sample program that parses a JSON file and reports how much memory it uses before exiting.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">import</span> <span class="dt">Control.Monad</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">import</span> <span class="dt">Data.Aeson</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">import</span> <span class="dt">GHC.Stats</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw">import</span> <span class="dt">System.Posix.Process</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="kw">import</span> <span class="dt">System.Process</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"></a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="kw">import</span> <span class="kw">qualified</span> <span class="dt">Data.ByteString.Lazy</span> <span class="kw">as</span> <span class="dt">BS</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="kw">import</span> <span class="kw">qualified</span> <span class="dt">System.Environment</span>   <span class="kw">as</span> <span class="dt">IO</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"></a>
<a class="sourceLine" id="cb1-10" data-line-number="10"><span class="ot">main ::</span> <span class="dt">IO</span> ()</a>
<a class="sourceLine" id="cb1-11" data-line-number="11">main <span class="fu">=</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb1-12" data-line-number="12">  pid <span class="ot">&lt;-</span> getProcessID</a>
<a class="sourceLine" id="cb1-13" data-line-number="13">  (filename<span class="fu">:</span>_) <span class="ot">&lt;-</span> <span class="dt">IO</span><span class="fu">.</span>getArgs</a>
<a class="sourceLine" id="cb1-14" data-line-number="14">  bs <span class="ot">&lt;-</span> BS.readFile filename</a>
<a class="sourceLine" id="cb1-15" data-line-number="15">  <span class="kw">let</span> <span class="fu">!</span>maybeJson <span class="fu">=</span> decode<span class="ot"> bs ::</span> <span class="dt">Maybe</span> <span class="dt">Value</span></a>
<a class="sourceLine" id="cb1-16" data-line-number="16"></a>
<a class="sourceLine" id="cb1-17" data-line-number="17">  system <span class="fu">$</span> <span class="st">&quot;ps aux | grep &quot;</span> <span class="fu">&lt;&gt;</span> show pid <span class="fu">&lt;&gt;</span> <span class="st">&quot; | grep -v grep&quot;</span></a>
<a class="sourceLine" id="cb1-18" data-line-number="18"></a>
<a class="sourceLine" id="cb1-19" data-line-number="19">  forM_ maybeJson <span class="fu">$</span> \_ <span class="ot">-&gt;</span></a>
<a class="sourceLine" id="cb1-20" data-line-number="20">    putStrLn <span class="st">&quot;Done&quot;</span></a></code></pre></div>
<p>This program is used to parse a <code>25MB</code> file as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb2-1" data-line-number="1">$ <span class="fu">git</span> clone git@github.com:haskell-works/blog-examples.git</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">$ <span class="bu">cd</span> blog-examples/simple-json</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">$ <span class="ex">stack</span> build</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">$ <span class="ex">curl</span> https://data.medicare.gov/api/views/ijh5-nb2v/rows.json\?accessType\=DOWNLOAD <span class="op">&gt;</span> hospitalisation.json</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">$ <span class="fu">ls</span> -lh hospitalisation.json</a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="ex">-rw-r--r--</span>  1 jky  staff    25M 24 Jul 22:00 hospitalisation.json</a>
<a class="sourceLine" id="cb2-7" data-line-number="7">$ <span class="ex">stack</span> exec simple-json hospitalisation.json</a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="ex">jky</span>              32237 394.0  1.9 1078037040 323084 s001  S+   10:05pm   0:03.79 /Users/jky/wrk/haskell-works/blog-examples/simple-json/.stack-work/install/x86_64-osx/lts-12.2/8.4.3/bin/simple-json hospitalisation.json</a>
<a class="sourceLine" id="cb2-9" data-line-number="9"><span class="ex">Done</span></a></code></pre></div>
<p>The program self-reports that after parsing the file, it is using <code>394MB</code> of memory!</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" data-line-number="1">$ <span class="bu">time</span> gzip hospitalisation.json</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="fu">gzip</span> hospitalisation.json  0.55s user 0.02s system 96% cpu 0.595 total</a></code></pre></div>
<p>The discrepancy is even larger if we consider that large files stored in S3 are often compressed:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb4-1" data-line-number="1">$ <span class="fu">gzip</span> hospitalisation.json</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">$ <span class="fu">ls</span> -lh hospitalisation.json.gz</a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="ex">-rw-r--r--</span>  1 jky  staff   4.5M 24 Jul 22:00 hospitalisation.json.gz</a></code></pre></div>
<p>So now we’re look at unzipping and then parsing at a memory cost of <code>394M</code>, or <code>87x</code> the size of the compressed <code>4.5MB</code> file or <code>16x</code> the the size of the original <code>25MB</code> file.</p>
<h2 id="why-does-this-happen">Why does this happen</h2>
<p>JSON is hardly a compact serialisation format to start with, so the amount of memory required for parsing is quite astonishing.</p>
<p>Let’s take a look at the data type that describes that data that composes a typical JSON document:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">data</span> <span class="dt">Json</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">  <span class="fu">=</span> <span class="dt">JsonString</span> <span class="dt">String</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3">  <span class="fu">|</span> <span class="dt">JsonNumber</span> <span class="dt">Double</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4">  <span class="fu">|</span> <span class="dt">JsonObject</span> [(<span class="dt">String</span>, <span class="dt">Json</span>)]</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">  <span class="fu">|</span> <span class="dt">JsonArray</span> [<span class="dt">Json</span>]</a>
<a class="sourceLine" id="cb5-6" data-line-number="6">  <span class="fu">|</span> <span class="dt">JsonBool</span> <span class="dt">Bool</span></a>
<a class="sourceLine" id="cb5-7" data-line-number="7">  <span class="fu">|</span> <span class="dt">JsonNull</span></a>
<a class="sourceLine" id="cb5-8" data-line-number="8">  <span class="kw">deriving</span> (<span class="dt">Eq</span>, <span class="dt">Show</span>)</a></code></pre></div>
<p>This can be explained by the cost of pointers.</p>
<p>A large document, will have lots of pointers connecting all the JSON nodes and they cost 64-bits each on modern CPU architectures.</p>
<p>The image below constrasts the amount of memory allocated to actual data (green) versus the amount of memory allocated to pointers (purple) and other housekeeping information maintained by the runtime (blue).</p>
<figure>
<img src="/images/json-object-on-the-heap.png" alt="JSON Object on the Heap" /><figcaption>JSON Object on the Heap</figcaption>
</figure>
<p>The header exists because the <code>Json</code> type is a tagged type and the runtime needs a place to store additional information (the tag) to know which constructor is relevant for interpreting the payload.</p>
<ul>
<li>A <code>JsonBool</code> could theoretically be represented by one bit if represented as an unboxed and packed 1-bit integer. But given that Haskell’s <code>Bool</code> is a data type with two constructors, it is likely to be represented as a pointer to a <code>True</code> or <code>False</code> value as depicted here in green following the header, totalling 16-bytes.</li>
<li>A <code>JsonNumber</code> might be represented in 8 bytes, but with the header, it is still 16-bytes.</li>
<li>A <code>JsonString</code> is especially egrerious especially because it uses the <code>String</code> type but other representations like <code>Text</code>, whilst improvement, still leaves a lot of overhead.</li>
<li>A <code>JsonArray</code> is going to introduce a lot of overhead, because the payload typically is typed with <code>[Json]</code>, and the cons cells use to construct a list will use a lot of memory for headers and pointers per element. Imagine how much member an array like [1,2,3,4,5] would use!</li>
</ul>
<p>More information our how GHC allocates memory can be found <a href="https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects">here</a>.</p>
<p>Hopefully, these examples have convinced you of the absurdity of using in-memory documents to represent large datasets.</p>
<h1 id="cpu-usage-and-io-boundedness">CPU usage and IO boundedness</h1>
<p>Another point of consideration when parsing large datasets is how long it takes to parse the file. Often we would just dismiss the slowness to the parsing being IO bound, but is it really?</p>
<p>Here we measure how long it takes to parse a <code>25MB</code> JSON file (on my Macbook Pro):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb6-1" data-line-number="1">$ <span class="bu">time</span> stack exec simple-json hospitalisation.json <span class="op">&gt;</span> /dev/null</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="ex">stack</span> exec simple-json hospitalisation.json <span class="op">&gt;</span> /dev/null  2.96s user 1.21s system 328% cpu 1.270 total</a></code></pre></div>
<p>At <code>8.44 MB/s</code> (from <code>25 MB / 2.96 s</code>), is that fast or close to IO bound?</p>
<p>Not even close.</p>
<p>Below, we see that command line tool <code>cut</code> can select the first two columns out of a CSV file at a rate of <code>76MiB/s</code>, almost an order of magnitude faster.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb7-1" data-line-number="1">$ <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="kw">|</span> <span class="fu">cut</span> -d , -f 1 -f 2 <span class="op">&gt;</span> /dev/null</a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="ex">7.08GiB</span> 0:01:35 [76.0MiB/s]</a></code></pre></div>
<p>Are we IO bound yet?</p>
<p>Other programs are faster. For example:</p>
<p>Character count:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb8-1" data-line-number="1">$ <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="kw">|</span> <span class="fu">wc</span> -c <span class="op">&gt;</span> /dev/null</a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="ex">7.08GiB</span> 0:00:24 [ 298MiB/s]</a></code></pre></div>
<p>Line count:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb9-1" data-line-number="1">$ <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="kw">|</span> <span class="fu">wc</span> -l <span class="op">&gt;</span> /dev/null</a>
<a class="sourceLine" id="cb9-2" data-line-number="2"><span class="ex">7.08GiB</span> 0:00:08 [ 819MiB/s]</a></code></pre></div>
<p>Or remove <code>wc</code> altogether so we just have <code>cat</code> and <code>pv</code>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb10-1" data-line-number="1">$ <span class="fu">cat</span> ~/7g.csv <span class="kw">|</span> <span class="ex">pv</span> -t -e -b -a <span class="op">&gt;</span> /dev/null</a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="ex">7.08GiB</span> 0:00:02 [2.56GiB/s]</a></code></pre></div>
<p>It’s probably safe to say, JSON parsing with a traditional style parser will, depending on the specifics of the hardware, be one to three orders of magnitude slower than speeds where it could be considered to be IO bound.</p>
<h1 id="where-to-from-here">Where to from here</h1>
<p>In the near future, I’d like to describe on this blog how the <code>haskell-works</code> parsing libraries address these and other problems, and future directions the libraries might take.</p>
<p>Among the topics I hope to explore are:</p>
<ul>
<li>how succinct data-structures can be used to parse files with a lot less memory</li>
<li>how succinct data-structures look internally</li>
<li>how to create a semi-index into files so that work used to parse a file can be re-used by later jobs</li>
<li>how the laziness of the Haskell language can be exploited to avoid parsing unused data</li>
<li>how validation, indexing and parsing can be different steps</li>
<li>how validation and indexing can be parallelised</li>
<li>how simd and bit-manipulation instructions can be used to optimise parsing and succinct data-structures</li>
</ul>]]></summary>
</entry>

</feed>
